{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754c99df",
   "metadata": {},
   "source": [
    "# <p align=\"center\">Siemens Sales Forecast</p>\n",
    "\n",
    "---\n",
    "\n",
    "## <p align=\"center\">*2 - Feature Selection & Modeling*</p>\n",
    "\n",
    "---\n",
    "\n",
    "### üë• **Team Members**\n",
    "- **Ana Farinha** *(Student Number: 20211514)*  \n",
    "- **Ant√≥nio Oliveira** *(Student Number: 20211595)*  \n",
    "- **Mariana Neto** *(Student Number: 20211527)*  \n",
    "- **Salvador Domingues** *(Student Number: 20240597)*  \n",
    "\n",
    "üìÖ **Date:** *April 1, 2025*  \n",
    "üìç **Prepared for:** *Siemens*  \n",
    "\n",
    "**GitHub Repo:** https://github.com/MGN19/Siemens-forecast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217ae9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:48:52.933704Z",
     "start_time": "2025-03-14T14:48:52.929415Z"
    }
   },
   "source": [
    "# ToC\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "1. [Import Libraries & Data](#1.-Import-Libraries-&-Data) <br><br>\n",
    "\n",
    "2. [Product Category #1](#Product-Category-#1) <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6957c6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:53.524977Z",
     "start_time": "2025-03-23T15:11:53.522506Z"
    }
   },
   "outputs": [],
   "source": [
    "## CELL TYPES (remover depois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea5f62",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3ea15",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b453a2e",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9202c2",
   "metadata": {},
   "source": [
    "# 1. Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9d458a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:20.043887Z",
     "start_time": "2025-03-26T09:14:10.721391Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import fs_modelling as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd9fc0",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34b24fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:22.120125Z",
     "start_time": "2025-03-26T09:14:22.030648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded y_train_36\n",
      "Loaded y_train_8\n",
      "Loaded y_train_20\n",
      "Loaded y_train_9\n",
      "Loaded y_train_4\n",
      "Loaded y_train_11\n",
      "Loaded y_train_5\n",
      "Loaded y_train_12\n",
      "Loaded y_train_13\n",
      "Loaded y_train_6\n",
      "Loaded y_train_16\n",
      "Loaded y_train_3\n",
      "Loaded y_train_1\n",
      "Loaded y_train_14\n",
      "Loaded y_val_1\n",
      "Loaded y_val_3\n",
      "Loaded y_val_6\n",
      "Loaded y_val_5\n",
      "Loaded y_val_4\n",
      "Loaded y_val_16\n",
      "Loaded y_val_14\n",
      "Loaded y_val_11\n",
      "Loaded y_val_13\n",
      "Loaded y_val_12\n",
      "Loaded y_val_36\n",
      "Loaded y_val_20\n",
      "Loaded y_val_9\n",
      "Loaded y_val_8\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('./data/X_train_data/X_train.csv', index_col = 'Unnamed: 0')\n",
    "X_val = pd.read_csv('./data/X_val_data/X_val.csv', index_col = 'Unnamed: 0')\n",
    "\n",
    "def import_all_csvs_as_vars(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.csv'):\n",
    "            df_name = file.replace('.csv', '')\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            globals()[df_name] = df\n",
    "            print(f\"Loaded {df_name}\")\n",
    "\n",
    "# Import each CSV file as individual DataFrames\n",
    "import_all_csvs_as_vars('data/y_train_data')\n",
    "import_all_csvs_as_vars('data/y_val_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998ca9d",
   "metadata": {},
   "source": [
    "# Product Category #1\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45896a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:23.273517Z",
     "start_time": "2025-03-26T09:14:23.270998Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = [X_train, X_val, y_train_1, y_val_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cb759",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35cad259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:30.675511Z",
     "start_time": "2025-03-26T09:14:30.665757Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_val_scaled = m.scale_data(X_train, \n",
    "                                          X_val, \n",
    "                                          scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e30c99",
   "metadata": {},
   "source": [
    "## 2.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c463d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:29:43.974670Z",
     "start_time": "2025-03-26T09:29:43.966864Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFdr, f_regression, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def feature_selection(X_train, y_train, method='all',\n",
    "                      rfe_model=None, corr_threshold=0.85, \n",
    "                      importance_threshold='mean', lasso_cv=True):\n",
    "    selected_features = []\n",
    "\n",
    "    if method == 'correlation':\n",
    "        corr_matrix = X_train.corr()\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        correlated_features = [column for column in upper_triangle.columns if any(upper_triangle[column].abs() > corr_threshold)]\n",
    "        selected_features = [col for col in X_train.columns if col not in correlated_features]\n",
    "        print(f'Selected {len(selected_features)} features by correlation')\n",
    "        \n",
    "    elif method == 'rfe':\n",
    "        if rfe_model is None:\n",
    "            rfe_model = LinearRegression()\n",
    "            \n",
    "        rfecv = RFECV(estimator=rfe_model, cv=10, scoring='neg_root_mean_squared_error')\n",
    "        rfecv.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfecv.support_]\n",
    "        print(f'Selected {len(selected_features)} features by RFECV')\n",
    "\n",
    "    elif method == 'importance':\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        if importance_threshold == 'mean':\n",
    "            threshold_value = np.mean(importances)\n",
    "        elif importance_threshold == 'median':\n",
    "            threshold_value = np.median(importances)\n",
    "        else:\n",
    "            threshold_value = float(importance_threshold)\n",
    "\n",
    "        selected_features = X_train.columns[importances > threshold_value]\n",
    "        print(f'Selected {len(selected_features)} features by importance with threshold {threshold_value}')\n",
    "\n",
    "    elif method == 'lasso':\n",
    "        lasso = LassoCV(cv=10, random_state=42).fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[lasso.coef_ != 0].tolist()\n",
    "        print(f'Selected {len(selected_features)} features by Lasso regularization')\n",
    "\n",
    "    elif method == 'all':\n",
    "        corr_features = feature_selection(X_train, y_train, method='correlation', corr_threshold=corr_threshold)\n",
    "        rfe_features = feature_selection(X_train, y_train, method='rfe', rfe_model=rfe_model)\n",
    "        importance_features = feature_selection(X_train, y_train, method='importance', importance_threshold=importance_threshold)\n",
    "        lasso_features = feature_selection(X_train, y_train, method='lasso')\n",
    "\n",
    "        selected_features = list(set(corr_features) & set(rfe_features) & set(importance_features) & set(lasso_features))\n",
    "        print(f'Selected {len(selected_features)} features that intersect across all methods')\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0686a3b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:31:32.885240Z",
     "start_time": "2025-03-26T09:30:21.592799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 42 features by correlation\n",
      "Selected 24 features by RFECV\n",
      "Selected 61 features by importance with threshold 0.0022862886632473304\n",
      "Selected 9 features by Lasso regularization\n",
      "Selected 3 features that intersect across all methods\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Clean_US', 'Fossil_Fra', 'USA Shipments Index']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = feature_selection(X_train_scaled, y_train_1, \n",
    "                                      method='all', \n",
    "                                      rfe_model = XGBRegressor(), \n",
    "                                      corr_threshold=0.85, \n",
    "                                      importance_threshold = 'median')\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b75280f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:24:13.030112Z",
     "start_time": "2025-03-26T09:24:10.638036Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet import Prophet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def modelling(X_train, y_train, X_test, y_test, \n",
    "              features_used, \n",
    "              metric='RMSE', \n",
    "              model_choice='arima', \n",
    "              save_path='./modelling_csvs/results.csv'):\n",
    "\n",
    "\n",
    "    # If ARIMA is chosen\n",
    "    if model_choice == 'arima':\n",
    "        if len(features_used) > 1:\n",
    "            raise ValueError('ARIMA only accepts 1 feature for the target variable.')\n",
    "        model = ARIMA(y_train, order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Predict\n",
    "        predictions = model_fit.forecast(len(y_test))\n",
    "        \n",
    "        # Calculate RMSE or any other metric\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        best_model_name = 'ARIMA'\n",
    "        best_score = rmse\n",
    "        print(f'ARIMA RMSE: {rmse}')\n",
    "\n",
    "    # Initialize LazyRegressor if 'lazy' model is chosen\n",
    "    elif model_choice == 'lazy':\n",
    "        regressor = LazyRegressor(verbose=0)\n",
    "        models, predictions = regressor.fit(X_train[features_used], X_test[features_used], y_train, y_test)\n",
    "        \n",
    "        # Select the best model based on the metric\n",
    "        best_model = models.sort_values(by=metric).iloc[0]\n",
    "        best_model_name = best_model.name\n",
    "        best_score = best_model[metric]\n",
    "        print(f'Best model: {best_model_name}')\n",
    "        print(f'{metric} of the best model: {best_score}')\n",
    "    \n",
    "    # If Prophet is chosen\n",
    "    elif model_choice == 'prophet':\n",
    "        raise ValueError('NOT WORKING YET')\n",
    "        # Initialize an empty DataFrame to hold future feature values\n",
    "        future_features = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each column in 'features_used'\n",
    "        for column in features_used:\n",
    "            # Isolate the current column into a new DataFrame 'df1'\n",
    "            df1 = X_train[[column]].copy()\n",
    "\n",
    "            # Reset the index of 'df1' and rename columns to fit Prophet's expected format\n",
    "            data = (df1.reset_index()\n",
    "                    .rename(columns={'index': 'ds', f'{column}': 'y'}))\n",
    "\n",
    "            # Initialize Prophet model\n",
    "            model = Prophet()\n",
    "\n",
    "            # Fit the model to the data\n",
    "            model.fit(data)\n",
    "\n",
    "            # Create a DataFrame representing future dates to make predictions\n",
    "            future = model.make_future_dataframe(periods=10, freq='MS')\n",
    "\n",
    "            # Forecast future dates\n",
    "            forecast_index = model.predict(future)\n",
    "\n",
    "            forecast_index = forecast_index[['ds', 'yhat']]\n",
    "            \n",
    "            # Set the date column as the index\n",
    "            forecast_index = forecast_index.set_index('ds')\n",
    "\n",
    "            # Add the forecasted values to the 'future_features' DataFrame\n",
    "            future_features[column] = forecast_index['yhat'].values\n",
    "\n",
    "        # Reset the index to use date as a regular column\n",
    "        future_features.reset_index(inplace=True)\n",
    "\n",
    "        # Add the date column to 'future_features'\n",
    "        future_features['ds'] = forecast_index['ds'].values\n",
    "\n",
    "        # Set date as the index of 'future_features'\n",
    "        future_features.set_index('ds', inplace=True)\n",
    "\n",
    "        # For demonstration, using RMSE here:\n",
    "        predicted_values = future_features[features_used].mean(axis=1)  # For simplicity, take the mean of all predictions\n",
    "        rmse = mean_squared_error(y_test, predicted_values, squared=False)\n",
    "        \n",
    "        # Compare RMSE to get best model\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_model_name = 'prophet'\n",
    "            \n",
    "    # Prepare row to save\n",
    "    result_row = {\n",
    "        'Features Used': ', '.join(features_used),\n",
    "        'Best Model': best_model_name,\n",
    "        metric: best_score\n",
    "    }\n",
    "    \n",
    "    # Check if file exists; if not, create with headers\n",
    "    if not os.path.isfile(save_path):\n",
    "        results_df = pd.DataFrame([result_row])\n",
    "        results_df.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        # Append without overwriting\n",
    "        results_df = pd.DataFrame([result_row])\n",
    "        results_df.to_csv(save_path, mode='a', header=False, index=False)\n",
    "    \n",
    "    return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "341ece87-c8ad-4b56-ba7f-ad5cdbd6260b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:01<00:00, 38.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 36294712.838710\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best model: SVR\n",
      "RMSE of the best model: 2887703.6389336362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_name, best_score  = modelling(X_train_scaled, y_train_1, X_val_scaled, y_val_1, \n",
    "              features_used=selected_features, \n",
    "              metric='RMSE', \n",
    "              model_choice='lazy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb18eb30-2c80-4ea0-8374-87151d56e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def prophet_forecast(X_train, y_train, features_used, periods=10, freq='MS'):\n",
    "    \"\"\"\n",
    "    Function to perform forecasting using Prophet for each feature in 'features_used'.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: DataFrame containing the training data\n",
    "    - y_train: Actual ground truth values for RMSE calculation (training data)\n",
    "    - features_used: List of features/columns to forecast using Prophet\n",
    "    - periods: Number of future periods to predict (default=10)\n",
    "    - freq: Frequency of the periods (default='MS' for monthly start)\n",
    "\n",
    "    Returns:\n",
    "    - best_model_name: Name of the best model ('prophet')\n",
    "    - best_score: The lowest RMSE score for the model\n",
    "    \"\"\"\n",
    "    best_score = float('inf')\n",
    "    best_model_name = None\n",
    "\n",
    "    # Initialize an empty DataFrame to hold future feature values\n",
    "    future_features = pd.DataFrame()\n",
    "\n",
    "    # Iterate through each column in 'features_used'\n",
    "    for column in features_used:\n",
    "        # Isolate the current column into a new DataFrame 'df1'\n",
    "        df1 = X_train[[column]].copy()\n",
    "\n",
    "        # Reset the index of 'df1' and rename columns to fit Prophet's expected format\n",
    "        data = (df1.reset_index()\n",
    "                .rename(columns={'index': 'ds', f'{column}': 'y'}))\n",
    "\n",
    "        # Initialize Prophet model\n",
    "        model = Prophet()\n",
    "\n",
    "        # Fit the model to the data\n",
    "        model.fit(data)\n",
    "\n",
    "        # Create a DataFrame representing future dates to make predictions\n",
    "        future = model.make_future_dataframe(periods=periods, freq=freq)\n",
    "\n",
    "        # Forecast future dates\n",
    "        forecast_index = model.predict(future)\n",
    "\n",
    "        # Select relevant columns ('ds' for date, 'yhat' for predictions)\n",
    "        forecast_index = forecast_index[['ds', 'yhat']]\n",
    "\n",
    "        # Set the date column as the index\n",
    "        forecast_index = forecast_index.set_index('ds')\n",
    "\n",
    "        # Add the forecasted values to the 'future_features' DataFrame\n",
    "        future_features[column] = forecast_index['yhat'].values\n",
    "\n",
    "    # Reset the index of the future_features DataFrame to use 'ds' as a regular column\n",
    "    future_features.reset_index(inplace=True)\n",
    "\n",
    "    # Add the date column to 'future_features'\n",
    "    future_features['ds'] = forecast_index.index.values\n",
    "\n",
    "    # Set 'ds' as the index of 'future_features'\n",
    "    future_features.set_index('ds', inplace=True)\n",
    "\n",
    "    # Ensure we only compare the forecasted values against a valid subset of y_train\n",
    "    # For simplicity, we will compare the mean of the forecasted values to the corresponding `y_train` values\n",
    "    predicted_values = future_features[features_used].mean(axis=1)  # For simplicity, take the mean of all predictions\n",
    "\n",
    "    rmse = mean_squared_error(y_train, predicted_values)\n",
    "\n",
    "    # Compare RMSE to get the best model\n",
    "    if rmse < best_score:\n",
    "        best_score = rmse\n",
    "        best_model_name = 'prophet'\n",
    "\n",
    "    return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b5d595e-afad-4036-9532-7170a4592007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:44:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31, 41]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprophet_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mprophet_forecast\u001b[39m\u001b[34m(X_train, y_train, features_used, periods, freq)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Ensure we only compare the forecasted values against a valid subset of y_train\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# For simplicity, we will compare the mean of the forecasted values to the corresponding `y_train` values\u001b[39;00m\n\u001b[32m     67\u001b[39m predicted_values = future_features[features_used].mean(axis=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# For simplicity, take the mean of all predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Compare RMSE to get the best model\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rmse < best_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:565\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    516\u001b[39m \n\u001b[32m    517\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    561\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    563\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    564\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m )\n\u001b[32m    569\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    570\u001b[39m output_errors = _average((y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:198\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03mregression task.\u001b[39;00m\n\u001b[32m    150\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m y_type, y_true, y_pred, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:104\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, multioutput, dtype, xp)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    106\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [31, 41]"
     ]
    }
   ],
   "source": [
    "prophet_forecast(X_train_1_scaled, y_train_1, selected_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd585af-d3c1-40a5-8034-45d5b0d76496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cd7e059-cb3c-436a-a042-c3061d431445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.14.4-cp313-cp313-macosx_10_13_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (2.2.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (1.15.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Using cached statsmodels-0.14.4-cp313-cp313-macosx_10_13_x86_64.whl (10.2 MB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "855ac6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:42:17.540624Z",
     "start_time": "2025-03-25T10:42:16.316552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:01<00:00, 34.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 36289610.258065\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best model: SVR\n",
      "RMSE of the best model: 2887703.8751545465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_1_selected = X_train_1_scaled[selected_features]\n",
    "X_val_1_selected = X_val_1_scaled[selected_features]\n",
    "\n",
    "best_model_name, best_score = modelling(\n",
    "    X_train_1_selected, y_train_1, X_val_1_selected, y_val_1, \n",
    "    features_used=selected_features, metric='RMSE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18f4288a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:53:41.960098Z",
     "start_time": "2025-03-23T15:53:41.955735Z"
    }
   },
   "outputs": [],
   "source": [
    "# import lazypredict\n",
    "# from lazypredict.Supervised import LazyRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# def lazy_regressor(X_train, y_train, X_test, y_test, metric='RMSE'):\n",
    "    \n",
    "#     # Initialize LazyRegressor\n",
    "#     regressor = LazyRegressor(verbose=0)\n",
    "    \n",
    "#     # Fit the model\n",
    "#     models, predictions = regressor.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "#     # Select the best model based on the metric (e.g., RMSE)\n",
    "#     best_model = models.sort_values(by=metric).iloc[0]\n",
    "    \n",
    "#     # Get the model name and the best score\n",
    "#     best_model_name = best_model.name\n",
    "#     best_score = best_model[metric]\n",
    "    \n",
    "#     print(f'Best model: {best_model_name}')\n",
    "#     print(f'{metric} of the best model: {best_score}')\n",
    "    \n",
    "#     # Return the best model and score\n",
    "#     return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9110ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:53:44.734147Z",
     "start_time": "2025-03-23T15:53:42.340731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:02<00:00, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 36289610.258065\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best model: GradientBoostingRegressor\n",
      "RMSE of the best model: 2847141.438462039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# best_model_name, best_score = lazy_regressor(X_train_1_scaled, y_train_1,\n",
    "#                                              X_val_1_scaled, y_val_1,\n",
    "#                                              metric='RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cf56a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:42:19.884930Z",
     "start_time": "2025-03-25T10:42:19.877181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(W) Price of Base Metals, GER Production Index...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA Shipments Index_Rolling_Mean_3</td>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>2823366.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BC_CHI, USA Shipments Index_Rolling_Mean_3, CH...</td>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>2830173.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(W) Price of Base Metals, GER Production Index...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(W) Price of Natural gas index, USA Production...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Features Used      Best Model  \\\n",
       "0  (W) Price of Base Metals, GER Production Index...             SVR   \n",
       "1                 USA Shipments Index_Rolling_Mean_3  HuberRegressor   \n",
       "2  BC_CHI, USA Shipments Index_Rolling_Mean_3, CH...  HuberRegressor   \n",
       "3  (W) Price of Base Metals, GER Production Index...             SVR   \n",
       "4  (W) Price of Natural gas index, USA Production...             SVR   \n",
       "\n",
       "        RMSE  \n",
       "0 2887703.96  \n",
       "1 2823366.38  \n",
       "2 2830173.62  \n",
       "3 2887703.92  \n",
       "4 2887703.88  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('./lazy_regressor_results.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85584d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:02:28.834869Z",
     "start_time": "2025-03-23T16:02:28.801224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautosklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maskl2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterAutoregMultiSeries\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "from autosklearn.experimental.askl2 import ForecasterAutoregMultiSeries\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def time_series_forecasting(X_train, y_train, X_test, y_test, \n",
    "                            forecast_steps=10, metric='neg_root_mean_squared_error'):\n",
    "\n",
    "    # Initialize ForecasterAutoregMultiSeries\n",
    "    forecaster = ForecasterAutoregMultiSeries(steps=forecast_steps, metric=metric)\n",
    "    \n",
    "    # Fit the forecaster with training data\n",
    "    forecaster.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = forecaster.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'Test RMSE: {rmse}')\n",
    "    \n",
    "    return forecaster, y_pred, rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633116",
   "metadata": {},
   "source": [
    "### 2.1.1 Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b2ec6",
   "metadata": {},
   "source": [
    "**Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bec66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.216711Z",
     "start_time": "2025-03-23T15:11:56.216700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_1_scaled.var() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5dced",
   "metadata": {},
   "source": [
    "**Spearman Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e397f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.218093Z",
     "start_time": "2025-03-23T15:11:56.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_matrix(X, cmap='YlOrBr', font_size = 5):\n",
    "    \"\"\"\n",
    "    Input: X (numerical data)\n",
    "    Output: Correlation Matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Plot Heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": font_size})\n",
    "    plt.title(\"Feature Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379196d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.219727Z",
     "start_time": "2025-03-23T15:11:56.219713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5e958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.220921Z",
     "start_time": "2025-03-23T15:11:56.220910Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_correlated_features(X, top_n=20, cmap='YlOrBr'):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    mean_corr = corr_matrix.mean().sort_values(ascending=False)\n",
    "    top_features = mean_corr.head(top_n).index\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(X[top_features].corr(), annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": 8})\n",
    "    plt.title(f\"Top {top_n} Most Correlated Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365f2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.222515Z",
     "start_time": "2025-03-23T15:11:56.222501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_correlated_features(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80988409",
   "metadata": {},
   "source": [
    "### 2.2.2 Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed569a6",
   "metadata": {},
   "source": [
    "**RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f909060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.224068Z",
     "start_time": "2025-03-23T15:11:56.224057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def rfe(X_train, y_train, X_val, y_val, n_features, model=None):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X_train, y_train, X_val, y_val: training and validation data\n",
    "        n_features: number of features to use for RFE\n",
    "        model: chosen regression model \n",
    "    Output: selected features for the best model based on RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    best_rmse = np.inf  # Start with a very high RMSE (lower is better)\n",
    "    best_features = []\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for feature in n_features:\n",
    "        \n",
    "        # Fit RFE\n",
    "        rfe = RFE(estimator=model, n_features_to_select=feature)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        # Get selected features\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "        \n",
    "        print('\\n-------------TRAIN-------------')\n",
    "\n",
    "        # Predictions for Train\n",
    "        y_pred_train = rfe.predict(X_train)\n",
    "        \n",
    "        # Metrics for Training (RMSE)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Train): {rmse_train:.4f}\")\n",
    "        \n",
    "        print('----------VALIDATION----------')\n",
    "\n",
    "        # Predictions for Validation\n",
    "        y_pred_val = rfe.predict(X_val)\n",
    "        \n",
    "        # Metrics for Validation (RMSE)\n",
    "        mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "        rmse_val = np.sqrt(mse_val)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Validation): {rmse_val:.4f}\")\n",
    "        \n",
    "        # Best score based on RMSE (lower is better)\n",
    "        if rmse_val < best_rmse:\n",
    "            best_rmse = rmse_val\n",
    "            best_features = selected_features.tolist()  \n",
    "        \n",
    "    print('\\n----------FINAL----------')\n",
    "    print(f'Best RMSE: {best_rmse}')\n",
    "    print(f'Number of Features: {len(best_features)}')\n",
    "    print(f'Features: {best_features}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.225027Z",
     "start_time": "2025-03-23T15:11:56.225016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = LinearRegression()\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.226165Z",
     "start_time": "2025-03-23T15:11:56.226154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = XGBRegressor(objective='reg:squarederror',\n",
    "                     random_state = 100)\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954c798",
   "metadata": {},
   "source": [
    "### 2.2.3 Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3119f7",
   "metadata": {},
   "source": [
    "**LASSO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbeb421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.227721Z",
     "start_time": "2025-03-23T15:11:56.227707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import functions as f\n",
    "def lasso(X, y, alpha = 0.01, color = f.main_color):\n",
    "\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X, y: data\n",
    "        alpha: parameter for lasso\n",
    "    Output: Plot, initial and selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    # Get Feature Importance\n",
    "    importance = pd.Series(lasso.coef_, index=X.columns)\n",
    "    importance.sort_values().plot(kind=\"barh\", color=color)\n",
    "    non_zero_importance = importance[importance != 0]\n",
    "    selected_features = non_zero_importance.index\n",
    "\n",
    "    # Plot\n",
    "    plt.title(\"Lasso Feature Importance\")\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Results\n",
    "    print(f\"\\nInitial Features: {len(X.columns)}\\n\")\n",
    "    print(X.columns.tolist())\n",
    "    print(f\"\\nDecision for Numerical Features (lasso ‚â† 0): {len(selected_features.tolist())}\\n\")\n",
    "    print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614a16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.228825Z",
     "start_time": "2025-03-23T15:11:56.228814Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso(X_train_1_scaled, y_train_1, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969aaa2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a97773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.230110Z",
     "start_time": "2025-03-23T15:11:56.230099Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(X_train_1_scaled, y_train_1)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val_1 = model.predict(X_val_1_scaled)\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse_val_1 = np.sqrt(mean_squared_error(y_val_1, y_pred_val_1))\n",
    "print(f'Root Mean Squared Error on Validation Set: {rmse_val_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e9ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.231315Z",
     "start_time": "2025-03-23T15:11:56.231303Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(y_val_1.index, y_val_1, label='Actual Validation Values', linestyle='-', color='g')\n",
    "plt.plot(y_val_1.index, y_pred_val_1, label='Predicted Validation Values', linestyle='--', color='g')\n",
    "\n",
    "plt.plot(y_train_1.index, y_train_1, label='Actual Training Values', linestyle='-', color='b')\n",
    "\n",
    "plt.xlabel('Date/Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('XGBoost Forecasting: Actual vs Predicted (Training and Validation)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
