{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754c99df",
   "metadata": {},
   "source": [
    "# <p align=\"center\">Siemens Sales Forecast</p>\n",
    "\n",
    "---\n",
    "\n",
    "## <p align=\"center\">*2 - Feature Selection & Modeling*</p>\n",
    "\n",
    "---\n",
    "\n",
    "### üë• **Team Members**\n",
    "- **Ana Farinha** *(Student Number: 20211514)*  \n",
    "- **Ant√≥nio Oliveira** *(Student Number: 20211595)*  \n",
    "- **Mariana Neto** *(Student Number: 20211527)*  \n",
    "- **Salvador Domingues** *(Student Number: 20240597)*  \n",
    "\n",
    "üìÖ **Date:** *April 1, 2025*  \n",
    "üìç **Prepared for:** *Siemens*  \n",
    "\n",
    "**GitHub Repo:** https://github.com/MGN19/Siemens-forecast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217ae9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:48:52.933704Z",
     "start_time": "2025-03-14T14:48:52.929415Z"
    }
   },
   "source": [
    "# ToC\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "1. [Import Libraries & Data](#1.-Import-Libraries-&-Data) <br><br>\n",
    "\n",
    "2. [Product Category #1](#Product-Category-#1) <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6957c6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:53.524977Z",
     "start_time": "2025-03-23T15:11:53.522506Z"
    }
   },
   "outputs": [],
   "source": [
    "## CELL TYPES (remover depois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea5f62",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3ea15",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b453a2e",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9202c2",
   "metadata": {},
   "source": [
    "# 1. Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9d458a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:20.043887Z",
     "start_time": "2025-03-26T09:14:10.721391Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import fs_modelling as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd9fc0",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34b24fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:22.120125Z",
     "start_time": "2025-03-26T09:14:22.030648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_8_diff', 'df_14', 'df_16', 'df_12', 'df_13', 'df_9', 'df_11', 'df_8', 'df_5', 'df_20', 'df_4', 'df_36', 'df_6', 'df_3', 'df_1']\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/individual_dfs/'\n",
    "\n",
    "# List to store the names of each dataframe\n",
    "imported_df_names = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        df_name = file.replace('.csv', '')  # Get name without .csv\n",
    "        df_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read CSV and assign to a variable\n",
    "        globals()[df_name] = pd.read_csv(df_path, index_col=0)\n",
    "        \n",
    "        # Store the dataframe name in the list\n",
    "        imported_df_names.append(df_name)\n",
    "\n",
    "# Convert the index of all DataFrames to datetime\n",
    "for df_name in imported_df_names:\n",
    "    globals()[df_name].index = pd.to_datetime(globals()[df_name].index)\n",
    "\n",
    "# Optional: print to check\n",
    "print(imported_df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998ca9d",
   "metadata": {},
   "source": [
    "# Product Category #1\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45896a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:23.273517Z",
     "start_time": "2025-03-26T09:14:23.270998Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.reset_option('display.max_rows', None)\n",
    "# df_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e78bb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:23.645570Z",
     "start_time": "2025-03-26T09:14:23.589194Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1</th>\n",
       "      <th>CHI Production Index</th>\n",
       "      <th>CHI Shipments Index</th>\n",
       "      <th>FRA Production Index</th>\n",
       "      <th>FRA Shipments Index</th>\n",
       "      <th>GER Production Index</th>\n",
       "      <th>GER Shipments Index</th>\n",
       "      <th>ITA Production Index</th>\n",
       "      <th>ITA Shipments Index</th>\n",
       "      <th>JAP Production Index</th>\n",
       "      <th>JAP Shipments Index</th>\n",
       "      <th>SWI Production Index</th>\n",
       "      <th>SWI Shipments Index</th>\n",
       "      <th>UK Production Index</th>\n",
       "      <th>UK Shipments Index</th>\n",
       "      <th>USA Production Index</th>\n",
       "      <th>USA Shipments Index</th>\n",
       "      <th>Europe Production Index</th>\n",
       "      <th>Europe Shipments Index</th>\n",
       "      <th>(W) Price of Base Metals</th>\n",
       "      <th>(W) Price of Energy</th>\n",
       "      <th>(W) Price of Metals &amp; Minerals</th>\n",
       "      <th>(W) Price of Natural gas index</th>\n",
       "      <th>(W) Price of Crude oil, average</th>\n",
       "      <th>(W) Price of Copper</th>\n",
       "      <th>USA EUR to LCU Conversion Rate</th>\n",
       "      <th>USA EE Producer Prices</th>\n",
       "      <th>UK EE Producer Prices</th>\n",
       "      <th>ITA EE Producer Prices</th>\n",
       "      <th>FRA EE Producer Prices</th>\n",
       "      <th>GER EE Producer Prices</th>\n",
       "      <th>CHI EE Producer Prices</th>\n",
       "      <th>USA Machinery &amp; Equipment Index</th>\n",
       "      <th>(W) Machinery &amp; Equipment Index</th>\n",
       "      <th>SWI Machinery &amp; Equipment Index</th>\n",
       "      <th>UK Machinery &amp; Equipment Index</th>\n",
       "      <th>ITA Machinery &amp; Equipment Index</th>\n",
       "      <th>JAP Machinery &amp; Equipment Index</th>\n",
       "      <th>FRA Machinery &amp; Equipment Index</th>\n",
       "      <th>GER Machinery &amp; Equipment Index</th>\n",
       "      <th>USA EE Production Index</th>\n",
       "      <th>(W) EE Production Index</th>\n",
       "      <th>SWI EE Production Index</th>\n",
       "      <th>UK EE Production Index</th>\n",
       "      <th>ITA EE Production Index</th>\n",
       "      <th>JAP EE Production Index</th>\n",
       "      <th>FRA EE Production Index</th>\n",
       "      <th>GER EE Production Index</th>\n",
       "      <th>CHI Production Index_Rolling_Mean_3</th>\n",
       "      <th>CHI Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>FRA Production Index_Rolling_Mean_3</th>\n",
       "      <th>FRA Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>GER Production Index_Rolling_Mean_3</th>\n",
       "      <th>GER Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>ITA Production Index_Rolling_Mean_3</th>\n",
       "      <th>ITA Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>JAP Production Index_Rolling_Mean_3</th>\n",
       "      <th>JAP Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>SWI Production Index_Rolling_Mean_3</th>\n",
       "      <th>SWI Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>UK Production Index_Rolling_Mean_3</th>\n",
       "      <th>UK Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>USA Production Index_Rolling_Mean_3</th>\n",
       "      <th>USA Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>Europe Production Index_Rolling_Mean_3</th>\n",
       "      <th>Europe Shipments Index_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Base Metals_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Energy_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Metals &amp; Minerals_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Natural gas index_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Crude oil, average_Rolling_Mean_3</th>\n",
       "      <th>(W) Price of Copper_Rolling_Mean_3</th>\n",
       "      <th>USA EUR to LCU Conversion Rate _Rolling_Mean_3</th>\n",
       "      <th>USA EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>UK EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>ITA EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>FRA EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>GER EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>CHI EE Producer Prices_Rolling_Mean_3</th>\n",
       "      <th>USA Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>(W) Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>SWI Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>UK Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>ITA Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>JAP Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>FRA Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>GER Machinery &amp; Equipment Index_Rolling_Mean_3</th>\n",
       "      <th>USA EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>(W) EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>SWI EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>UK EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>ITA EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>JAP EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>FRA EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>GER EE Production Index_Rolling_Mean_3</th>\n",
       "      <th>CC_CHI</th>\n",
       "      <th>CC_FRA</th>\n",
       "      <th>CC_GER</th>\n",
       "      <th>CC_ITA</th>\n",
       "      <th>CC_JAP</th>\n",
       "      <th>CC_Europe</th>\n",
       "      <th>CC_SWI</th>\n",
       "      <th>CC_UK</th>\n",
       "      <th>CC_USA</th>\n",
       "      <th>BC_CHI</th>\n",
       "      <th>BC_FRA</th>\n",
       "      <th>BC_GER</th>\n",
       "      <th>BC_ITA</th>\n",
       "      <th>BC_JAP</th>\n",
       "      <th>BC_Europe</th>\n",
       "      <th>BC_SWI</th>\n",
       "      <th>BC_UK</th>\n",
       "      <th>BC_USA</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>stock_price_change</th>\n",
       "      <th>stock_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>36098918.79</td>\n",
       "      <td>211.955755</td>\n",
       "      <td>211.955755</td>\n",
       "      <td>108.280608</td>\n",
       "      <td>122.451734</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>137.741953</td>\n",
       "      <td>118.350514</td>\n",
       "      <td>122.456894</td>\n",
       "      <td>125.209957</td>\n",
       "      <td>124.793250</td>\n",
       "      <td>109.077781</td>\n",
       "      <td>104.594781</td>\n",
       "      <td>113.659322</td>\n",
       "      <td>112.318030</td>\n",
       "      <td>111.902540</td>\n",
       "      <td>127.808839</td>\n",
       "      <td>124.391967</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>86.102586</td>\n",
       "      <td>100.222169</td>\n",
       "      <td>79.354986</td>\n",
       "      <td>89.570796</td>\n",
       "      <td>97.072264</td>\n",
       "      <td>82.545082</td>\n",
       "      <td>1.1484</td>\n",
       "      <td>110.700409</td>\n",
       "      <td>111.463669</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.064743</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>96.318329</td>\n",
       "      <td>111.422638</td>\n",
       "      <td>131.340118</td>\n",
       "      <td>106.816937</td>\n",
       "      <td>110.893450</td>\n",
       "      <td>129.389221</td>\n",
       "      <td>131.503786</td>\n",
       "      <td>114.720810</td>\n",
       "      <td>127.461136</td>\n",
       "      <td>112.853256</td>\n",
       "      <td>129.325775</td>\n",
       "      <td>112.970843</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>93.001511</td>\n",
       "      <td>112.376774</td>\n",
       "      <td>97.849541</td>\n",
       "      <td>118.298233</td>\n",
       "      <td>202.967874</td>\n",
       "      <td>202.967874</td>\n",
       "      <td>91.380433</td>\n",
       "      <td>108.585140</td>\n",
       "      <td>119.151650</td>\n",
       "      <td>134.801449</td>\n",
       "      <td>94.859629</td>\n",
       "      <td>104.070613</td>\n",
       "      <td>122.745057</td>\n",
       "      <td>123.893424</td>\n",
       "      <td>106.056871</td>\n",
       "      <td>101.699118</td>\n",
       "      <td>108.542104</td>\n",
       "      <td>105.792730</td>\n",
       "      <td>111.222701</td>\n",
       "      <td>127.351648</td>\n",
       "      <td>114.021188</td>\n",
       "      <td>123.656133</td>\n",
       "      <td>85.406475</td>\n",
       "      <td>96.977598</td>\n",
       "      <td>78.306125</td>\n",
       "      <td>86.817312</td>\n",
       "      <td>94.117390</td>\n",
       "      <td>81.052581</td>\n",
       "      <td>1.156400</td>\n",
       "      <td>110.399208</td>\n",
       "      <td>113.306043</td>\n",
       "      <td>105.332520</td>\n",
       "      <td>102.234685</td>\n",
       "      <td>108.979309</td>\n",
       "      <td>96.556406</td>\n",
       "      <td>111.114087</td>\n",
       "      <td>126.254812</td>\n",
       "      <td>103.957632</td>\n",
       "      <td>106.873350</td>\n",
       "      <td>103.491381</td>\n",
       "      <td>129.015240</td>\n",
       "      <td>96.920474</td>\n",
       "      <td>122.241409</td>\n",
       "      <td>111.437871</td>\n",
       "      <td>124.392769</td>\n",
       "      <td>109.671657</td>\n",
       "      <td>111.565712</td>\n",
       "      <td>75.037896</td>\n",
       "      <td>109.960090</td>\n",
       "      <td>82.407338</td>\n",
       "      <td>113.485171</td>\n",
       "      <td>102.8056</td>\n",
       "      <td>98.94864</td>\n",
       "      <td>101.5778</td>\n",
       "      <td>101.7588</td>\n",
       "      <td>100.3849</td>\n",
       "      <td>100.7815</td>\n",
       "      <td>100.3180</td>\n",
       "      <td>100.6982</td>\n",
       "      <td>101.5022</td>\n",
       "      <td>98.79642</td>\n",
       "      <td>101.0451</td>\n",
       "      <td>101.7476</td>\n",
       "      <td>100.9696</td>\n",
       "      <td>101.5259</td>\n",
       "      <td>100.9295</td>\n",
       "      <td>102.0386</td>\n",
       "      <td>102.0568</td>\n",
       "      <td>101.2177</td>\n",
       "      <td>91.70</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>61460000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>37323903.07</td>\n",
       "      <td>220.519655</td>\n",
       "      <td>220.519655</td>\n",
       "      <td>99.636911</td>\n",
       "      <td>115.958210</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>142.732193</td>\n",
       "      <td>107.719260</td>\n",
       "      <td>120.132032</td>\n",
       "      <td>122.624695</td>\n",
       "      <td>123.289888</td>\n",
       "      <td>112.241491</td>\n",
       "      <td>107.656238</td>\n",
       "      <td>115.088417</td>\n",
       "      <td>112.801011</td>\n",
       "      <td>110.880401</td>\n",
       "      <td>117.675874</td>\n",
       "      <td>123.070091</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>83.841374</td>\n",
       "      <td>84.436807</td>\n",
       "      <td>77.500875</td>\n",
       "      <td>97.362468</td>\n",
       "      <td>78.841167</td>\n",
       "      <td>82.230939</td>\n",
       "      <td>1.1367</td>\n",
       "      <td>110.994026</td>\n",
       "      <td>111.668373</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.064743</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>95.370118</td>\n",
       "      <td>109.737129</td>\n",
       "      <td>129.976456</td>\n",
       "      <td>110.792831</td>\n",
       "      <td>112.119922</td>\n",
       "      <td>117.990173</td>\n",
       "      <td>127.880755</td>\n",
       "      <td>104.873100</td>\n",
       "      <td>132.987915</td>\n",
       "      <td>113.145294</td>\n",
       "      <td>128.236176</td>\n",
       "      <td>114.736013</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>84.133400</td>\n",
       "      <td>111.907535</td>\n",
       "      <td>91.155960</td>\n",
       "      <td>117.163727</td>\n",
       "      <td>210.631538</td>\n",
       "      <td>210.631538</td>\n",
       "      <td>101.849501</td>\n",
       "      <td>116.303882</td>\n",
       "      <td>123.394861</td>\n",
       "      <td>139.031154</td>\n",
       "      <td>110.511202</td>\n",
       "      <td>119.292963</td>\n",
       "      <td>125.221712</td>\n",
       "      <td>125.834291</td>\n",
       "      <td>109.077781</td>\n",
       "      <td>104.594781</td>\n",
       "      <td>112.351705</td>\n",
       "      <td>110.129539</td>\n",
       "      <td>111.255655</td>\n",
       "      <td>123.832687</td>\n",
       "      <td>121.483379</td>\n",
       "      <td>130.534349</td>\n",
       "      <td>84.828174</td>\n",
       "      <td>94.461159</td>\n",
       "      <td>78.100259</td>\n",
       "      <td>92.033611</td>\n",
       "      <td>90.420282</td>\n",
       "      <td>81.693476</td>\n",
       "      <td>1.150333</td>\n",
       "      <td>110.698324</td>\n",
       "      <td>112.384855</td>\n",
       "      <td>105.263153</td>\n",
       "      <td>102.098732</td>\n",
       "      <td>109.084536</td>\n",
       "      <td>96.088721</td>\n",
       "      <td>110.684954</td>\n",
       "      <td>129.945933</td>\n",
       "      <td>106.816937</td>\n",
       "      <td>110.075803</td>\n",
       "      <td>120.556625</td>\n",
       "      <td>131.247424</td>\n",
       "      <td>108.324875</td>\n",
       "      <td>127.729802</td>\n",
       "      <td>112.386248</td>\n",
       "      <td>127.968880</td>\n",
       "      <td>112.970843</td>\n",
       "      <td>116.475402</td>\n",
       "      <td>87.443151</td>\n",
       "      <td>112.935223</td>\n",
       "      <td>91.361465</td>\n",
       "      <td>115.444776</td>\n",
       "      <td>103.2386</td>\n",
       "      <td>98.71818</td>\n",
       "      <td>101.5438</td>\n",
       "      <td>101.6450</td>\n",
       "      <td>100.2850</td>\n",
       "      <td>100.6595</td>\n",
       "      <td>100.3069</td>\n",
       "      <td>100.4390</td>\n",
       "      <td>101.3958</td>\n",
       "      <td>98.45412</td>\n",
       "      <td>100.9598</td>\n",
       "      <td>101.5859</td>\n",
       "      <td>100.8509</td>\n",
       "      <td>101.5088</td>\n",
       "      <td>100.9174</td>\n",
       "      <td>101.8399</td>\n",
       "      <td>102.2486</td>\n",
       "      <td>101.0049</td>\n",
       "      <td>92.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>48250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>37889612.12</td>\n",
       "      <td>241.846854</td>\n",
       "      <td>241.846854</td>\n",
       "      <td>94.690312</td>\n",
       "      <td>115.128469</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>141.407661</td>\n",
       "      <td>88.783181</td>\n",
       "      <td>131.936099</td>\n",
       "      <td>122.991956</td>\n",
       "      <td>124.508413</td>\n",
       "      <td>115.405201</td>\n",
       "      <td>110.717696</td>\n",
       "      <td>101.556108</td>\n",
       "      <td>94.503733</td>\n",
       "      <td>106.257796</td>\n",
       "      <td>123.280134</td>\n",
       "      <td>113.858005</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>82.733389</td>\n",
       "      <td>74.898746</td>\n",
       "      <td>76.071705</td>\n",
       "      <td>94.406578</td>\n",
       "      <td>68.268564</td>\n",
       "      <td>80.630361</td>\n",
       "      <td>1.1384</td>\n",
       "      <td>111.162231</td>\n",
       "      <td>112.794266</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.166710</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>94.994885</td>\n",
       "      <td>103.448280</td>\n",
       "      <td>124.202469</td>\n",
       "      <td>114.768725</td>\n",
       "      <td>99.446384</td>\n",
       "      <td>99.191734</td>\n",
       "      <td>128.125679</td>\n",
       "      <td>104.974617</td>\n",
       "      <td>137.363281</td>\n",
       "      <td>111.823624</td>\n",
       "      <td>117.043549</td>\n",
       "      <td>116.501182</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>64.881248</td>\n",
       "      <td>112.524242</td>\n",
       "      <td>78.033028</td>\n",
       "      <td>89.626122</td>\n",
       "      <td>224.774088</td>\n",
       "      <td>224.774088</td>\n",
       "      <td>100.869277</td>\n",
       "      <td>117.846137</td>\n",
       "      <td>124.050192</td>\n",
       "      <td>140.627269</td>\n",
       "      <td>104.950985</td>\n",
       "      <td>124.841675</td>\n",
       "      <td>123.608869</td>\n",
       "      <td>124.197184</td>\n",
       "      <td>112.241491</td>\n",
       "      <td>107.656238</td>\n",
       "      <td>110.101282</td>\n",
       "      <td>106.540925</td>\n",
       "      <td>109.680246</td>\n",
       "      <td>122.921616</td>\n",
       "      <td>120.440021</td>\n",
       "      <td>131.728244</td>\n",
       "      <td>84.225783</td>\n",
       "      <td>86.519241</td>\n",
       "      <td>77.642522</td>\n",
       "      <td>93.779947</td>\n",
       "      <td>81.393998</td>\n",
       "      <td>81.802127</td>\n",
       "      <td>1.141167</td>\n",
       "      <td>110.952222</td>\n",
       "      <td>111.975436</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.098732</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>95.561111</td>\n",
       "      <td>108.202682</td>\n",
       "      <td>128.506348</td>\n",
       "      <td>110.792831</td>\n",
       "      <td>107.486585</td>\n",
       "      <td>115.523710</td>\n",
       "      <td>129.170074</td>\n",
       "      <td>108.189509</td>\n",
       "      <td>132.604111</td>\n",
       "      <td>112.607391</td>\n",
       "      <td>124.868500</td>\n",
       "      <td>114.736013</td>\n",
       "      <td>114.838838</td>\n",
       "      <td>80.672053</td>\n",
       "      <td>112.269517</td>\n",
       "      <td>89.012843</td>\n",
       "      <td>108.362694</td>\n",
       "      <td>103.6305</td>\n",
       "      <td>98.62968</td>\n",
       "      <td>101.5190</td>\n",
       "      <td>101.4642</td>\n",
       "      <td>100.1741</td>\n",
       "      <td>100.5454</td>\n",
       "      <td>100.1724</td>\n",
       "      <td>100.1360</td>\n",
       "      <td>101.2298</td>\n",
       "      <td>98.18901</td>\n",
       "      <td>100.8520</td>\n",
       "      <td>101.3715</td>\n",
       "      <td>100.7023</td>\n",
       "      <td>101.4458</td>\n",
       "      <td>100.8464</td>\n",
       "      <td>101.6098</td>\n",
       "      <td>102.3394</td>\n",
       "      <td>100.6920</td>\n",
       "      <td>87.78</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>48710000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     #1  CHI Production Index  CHI Shipments Index  \\\n",
       "2018-10-01  36098918.79            211.955755           211.955755   \n",
       "2018-11-01  37323903.07            220.519655           220.519655   \n",
       "2018-12-01  37889612.12            241.846854           241.846854   \n",
       "\n",
       "            FRA Production Index  FRA Shipments Index  GER Production Index  \\\n",
       "2018-10-01            108.280608           122.451734            124.227879   \n",
       "2018-11-01             99.636911           115.958210            127.404132   \n",
       "2018-12-01             94.690312           115.128469            120.518565   \n",
       "\n",
       "            GER Shipments Index  ITA Production Index  ITA Shipments Index  \\\n",
       "2018-10-01           137.741953            118.350514           122.456894   \n",
       "2018-11-01           142.732193            107.719260           120.132032   \n",
       "2018-12-01           141.407661             88.783181           131.936099   \n",
       "\n",
       "            JAP Production Index  JAP Shipments Index  SWI Production Index  \\\n",
       "2018-10-01            125.209957           124.793250            109.077781   \n",
       "2018-11-01            122.624695           123.289888            112.241491   \n",
       "2018-12-01            122.991956           124.508413            115.405201   \n",
       "\n",
       "            SWI Shipments Index  UK Production Index  UK Shipments Index  \\\n",
       "2018-10-01           104.594781           113.659322          112.318030   \n",
       "2018-11-01           107.656238           115.088417          112.801011   \n",
       "2018-12-01           110.717696           101.556108           94.503733   \n",
       "\n",
       "            USA Production Index  USA Shipments Index  \\\n",
       "2018-10-01            111.902540           127.808839   \n",
       "2018-11-01            110.880401           117.675874   \n",
       "2018-12-01            106.257796           123.280134   \n",
       "\n",
       "            Europe Production Index  Europe Shipments Index  \\\n",
       "2018-10-01               124.391967              130.989253   \n",
       "2018-11-01               123.070091              132.934130   \n",
       "2018-12-01               113.858005              131.261348   \n",
       "\n",
       "            (W) Price of Base Metals  (W) Price of Energy  \\\n",
       "2018-10-01                 86.102586           100.222169   \n",
       "2018-11-01                 83.841374            84.436807   \n",
       "2018-12-01                 82.733389            74.898746   \n",
       "\n",
       "            (W) Price of Metals & Minerals  (W) Price of Natural gas index  \\\n",
       "2018-10-01                       79.354986                       89.570796   \n",
       "2018-11-01                       77.500875                       97.362468   \n",
       "2018-12-01                       76.071705                       94.406578   \n",
       "\n",
       "            (W) Price of Crude oil, average  (W) Price of Copper  \\\n",
       "2018-10-01                        97.072264            82.545082   \n",
       "2018-11-01                        78.841167            82.230939   \n",
       "2018-12-01                        68.268564            80.630361   \n",
       "\n",
       "            USA EUR to LCU Conversion Rate   USA EE Producer Prices  \\\n",
       "2018-10-01                           1.1484              110.700409   \n",
       "2018-11-01                           1.1367              110.994026   \n",
       "2018-12-01                           1.1384              111.162231   \n",
       "\n",
       "            UK EE Producer Prices  ITA EE Producer Prices  \\\n",
       "2018-10-01             111.463669              105.297836   \n",
       "2018-11-01             111.668373              105.297836   \n",
       "2018-12-01             112.794266              105.297836   \n",
       "\n",
       "            FRA EE Producer Prices  GER EE Producer Prices  \\\n",
       "2018-10-01              102.064743              109.119614   \n",
       "2018-11-01              102.064743              109.224838   \n",
       "2018-12-01              102.166710              109.330063   \n",
       "\n",
       "            CHI EE Producer Prices  USA Machinery & Equipment Index  \\\n",
       "2018-10-01               96.318329                       111.422638   \n",
       "2018-11-01               95.370118                       109.737129   \n",
       "2018-12-01               94.994885                       103.448280   \n",
       "\n",
       "            (W) Machinery & Equipment Index  SWI Machinery & Equipment Index  \\\n",
       "2018-10-01                       131.340118                       106.816937   \n",
       "2018-11-01                       129.976456                       110.792831   \n",
       "2018-12-01                       124.202469                       114.768725   \n",
       "\n",
       "            UK Machinery & Equipment Index  ITA Machinery & Equipment Index  \\\n",
       "2018-10-01                      110.893450                       129.389221   \n",
       "2018-11-01                      112.119922                       117.990173   \n",
       "2018-12-01                       99.446384                        99.191734   \n",
       "\n",
       "            JAP Machinery & Equipment Index  FRA Machinery & Equipment Index  \\\n",
       "2018-10-01                       131.503786                       114.720810   \n",
       "2018-11-01                       127.880755                       104.873100   \n",
       "2018-12-01                       128.125679                       104.974617   \n",
       "\n",
       "            GER Machinery & Equipment Index  USA EE Production Index  \\\n",
       "2018-10-01                       127.461136               112.853256   \n",
       "2018-11-01                       132.987915               113.145294   \n",
       "2018-12-01                       137.363281               111.823624   \n",
       "\n",
       "            (W) EE Production Index  SWI EE Production Index  \\\n",
       "2018-10-01               129.325775               112.970843   \n",
       "2018-11-01               128.236176               114.736013   \n",
       "2018-12-01               117.043549               116.501182   \n",
       "\n",
       "            UK EE Production Index  ITA EE Production Index  \\\n",
       "2018-10-01              118.670791                93.001511   \n",
       "2018-11-01              120.467019                84.133400   \n",
       "2018-12-01              105.378705                64.881248   \n",
       "\n",
       "            JAP EE Production Index  FRA EE Production Index  \\\n",
       "2018-10-01               112.376774                97.849541   \n",
       "2018-11-01               111.907535                91.155960   \n",
       "2018-12-01               112.524242                78.033028   \n",
       "\n",
       "            GER EE Production Index  CHI Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01               118.298233                           202.967874   \n",
       "2018-11-01               117.163727                           210.631538   \n",
       "2018-12-01                89.626122                           224.774088   \n",
       "\n",
       "            CHI Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          202.967874   \n",
       "2018-11-01                          210.631538   \n",
       "2018-12-01                          224.774088   \n",
       "\n",
       "            FRA Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                            91.380433   \n",
       "2018-11-01                           101.849501   \n",
       "2018-12-01                           100.869277   \n",
       "\n",
       "            FRA Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          108.585140   \n",
       "2018-11-01                          116.303882   \n",
       "2018-12-01                          117.846137   \n",
       "\n",
       "            GER Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                           119.151650   \n",
       "2018-11-01                           123.394861   \n",
       "2018-12-01                           124.050192   \n",
       "\n",
       "            GER Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          134.801449   \n",
       "2018-11-01                          139.031154   \n",
       "2018-12-01                          140.627269   \n",
       "\n",
       "            ITA Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                            94.859629   \n",
       "2018-11-01                           110.511202   \n",
       "2018-12-01                           104.950985   \n",
       "\n",
       "            ITA Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          104.070613   \n",
       "2018-11-01                          119.292963   \n",
       "2018-12-01                          124.841675   \n",
       "\n",
       "            JAP Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                           122.745057   \n",
       "2018-11-01                           125.221712   \n",
       "2018-12-01                           123.608869   \n",
       "\n",
       "            JAP Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          123.893424   \n",
       "2018-11-01                          125.834291   \n",
       "2018-12-01                          124.197184   \n",
       "\n",
       "            SWI Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                           106.056871   \n",
       "2018-11-01                           109.077781   \n",
       "2018-12-01                           112.241491   \n",
       "\n",
       "            SWI Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          101.699118   \n",
       "2018-11-01                          104.594781   \n",
       "2018-12-01                          107.656238   \n",
       "\n",
       "            UK Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          108.542104   \n",
       "2018-11-01                          112.351705   \n",
       "2018-12-01                          110.101282   \n",
       "\n",
       "            UK Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                         105.792730   \n",
       "2018-11-01                         110.129539   \n",
       "2018-12-01                         106.540925   \n",
       "\n",
       "            USA Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                           111.222701   \n",
       "2018-11-01                           111.255655   \n",
       "2018-12-01                           109.680246   \n",
       "\n",
       "            USA Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                          127.351648   \n",
       "2018-11-01                          123.832687   \n",
       "2018-12-01                          122.921616   \n",
       "\n",
       "            Europe Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                              114.021188   \n",
       "2018-11-01                              121.483379   \n",
       "2018-12-01                              120.440021   \n",
       "\n",
       "            Europe Shipments Index_Rolling_Mean_3  \\\n",
       "2018-10-01                             123.656133   \n",
       "2018-11-01                             130.534349   \n",
       "2018-12-01                             131.728244   \n",
       "\n",
       "            (W) Price of Base Metals_Rolling_Mean_3  \\\n",
       "2018-10-01                                85.406475   \n",
       "2018-11-01                                84.828174   \n",
       "2018-12-01                                84.225783   \n",
       "\n",
       "            (W) Price of Energy_Rolling_Mean_3  \\\n",
       "2018-10-01                           96.977598   \n",
       "2018-11-01                           94.461159   \n",
       "2018-12-01                           86.519241   \n",
       "\n",
       "            (W) Price of Metals & Minerals_Rolling_Mean_3  \\\n",
       "2018-10-01                                      78.306125   \n",
       "2018-11-01                                      78.100259   \n",
       "2018-12-01                                      77.642522   \n",
       "\n",
       "            (W) Price of Natural gas index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      86.817312   \n",
       "2018-11-01                                      92.033611   \n",
       "2018-12-01                                      93.779947   \n",
       "\n",
       "            (W) Price of Crude oil, average_Rolling_Mean_3  \\\n",
       "2018-10-01                                       94.117390   \n",
       "2018-11-01                                       90.420282   \n",
       "2018-12-01                                       81.393998   \n",
       "\n",
       "            (W) Price of Copper_Rolling_Mean_3  \\\n",
       "2018-10-01                           81.052581   \n",
       "2018-11-01                           81.693476   \n",
       "2018-12-01                           81.802127   \n",
       "\n",
       "            USA EUR to LCU Conversion Rate _Rolling_Mean_3  \\\n",
       "2018-10-01                                        1.156400   \n",
       "2018-11-01                                        1.150333   \n",
       "2018-12-01                                        1.141167   \n",
       "\n",
       "            USA EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                             110.399208   \n",
       "2018-11-01                             110.698324   \n",
       "2018-12-01                             110.952222   \n",
       "\n",
       "            UK EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                            113.306043   \n",
       "2018-11-01                            112.384855   \n",
       "2018-12-01                            111.975436   \n",
       "\n",
       "            ITA EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                             105.332520   \n",
       "2018-11-01                             105.263153   \n",
       "2018-12-01                             105.297836   \n",
       "\n",
       "            FRA EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                             102.234685   \n",
       "2018-11-01                             102.098732   \n",
       "2018-12-01                             102.098732   \n",
       "\n",
       "            GER EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                             108.979309   \n",
       "2018-11-01                             109.084536   \n",
       "2018-12-01                             109.224838   \n",
       "\n",
       "            CHI EE Producer Prices_Rolling_Mean_3  \\\n",
       "2018-10-01                              96.556406   \n",
       "2018-11-01                              96.088721   \n",
       "2018-12-01                              95.561111   \n",
       "\n",
       "            USA Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      111.114087   \n",
       "2018-11-01                                      110.684954   \n",
       "2018-12-01                                      108.202682   \n",
       "\n",
       "            (W) Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      126.254812   \n",
       "2018-11-01                                      129.945933   \n",
       "2018-12-01                                      128.506348   \n",
       "\n",
       "            SWI Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      103.957632   \n",
       "2018-11-01                                      106.816937   \n",
       "2018-12-01                                      110.792831   \n",
       "\n",
       "            UK Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                     106.873350   \n",
       "2018-11-01                                     110.075803   \n",
       "2018-12-01                                     107.486585   \n",
       "\n",
       "            ITA Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      103.491381   \n",
       "2018-11-01                                      120.556625   \n",
       "2018-12-01                                      115.523710   \n",
       "\n",
       "            JAP Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      129.015240   \n",
       "2018-11-01                                      131.247424   \n",
       "2018-12-01                                      129.170074   \n",
       "\n",
       "            FRA Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                       96.920474   \n",
       "2018-11-01                                      108.324875   \n",
       "2018-12-01                                      108.189509   \n",
       "\n",
       "            GER Machinery & Equipment Index_Rolling_Mean_3  \\\n",
       "2018-10-01                                      122.241409   \n",
       "2018-11-01                                      127.729802   \n",
       "2018-12-01                                      132.604111   \n",
       "\n",
       "            USA EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                              111.437871   \n",
       "2018-11-01                              112.386248   \n",
       "2018-12-01                              112.607391   \n",
       "\n",
       "            (W) EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                              124.392769   \n",
       "2018-11-01                              127.968880   \n",
       "2018-12-01                              124.868500   \n",
       "\n",
       "            SWI EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                              109.671657   \n",
       "2018-11-01                              112.970843   \n",
       "2018-12-01                              114.736013   \n",
       "\n",
       "            UK EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                             111.565712   \n",
       "2018-11-01                             116.475402   \n",
       "2018-12-01                             114.838838   \n",
       "\n",
       "            ITA EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                               75.037896   \n",
       "2018-11-01                               87.443151   \n",
       "2018-12-01                               80.672053   \n",
       "\n",
       "            JAP EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                              109.960090   \n",
       "2018-11-01                              112.935223   \n",
       "2018-12-01                              112.269517   \n",
       "\n",
       "            FRA EE Production Index_Rolling_Mean_3  \\\n",
       "2018-10-01                               82.407338   \n",
       "2018-11-01                               91.361465   \n",
       "2018-12-01                               89.012843   \n",
       "\n",
       "            GER EE Production Index_Rolling_Mean_3    CC_CHI    CC_FRA  \\\n",
       "2018-10-01                              113.485171  102.8056  98.94864   \n",
       "2018-11-01                              115.444776  103.2386  98.71818   \n",
       "2018-12-01                              108.362694  103.6305  98.62968   \n",
       "\n",
       "              CC_GER    CC_ITA    CC_JAP  CC_Europe    CC_SWI     CC_UK  \\\n",
       "2018-10-01  101.5778  101.7588  100.3849   100.7815  100.3180  100.6982   \n",
       "2018-11-01  101.5438  101.6450  100.2850   100.6595  100.3069  100.4390   \n",
       "2018-12-01  101.5190  101.4642  100.1741   100.5454  100.1724  100.1360   \n",
       "\n",
       "              CC_USA    BC_CHI    BC_FRA    BC_GER    BC_ITA    BC_JAP  \\\n",
       "2018-10-01  101.5022  98.79642  101.0451  101.7476  100.9696  101.5259   \n",
       "2018-11-01  101.3958  98.45412  100.9598  101.5859  100.8509  101.5088   \n",
       "2018-12-01  101.2298  98.18901  100.8520  101.3715  100.7023  101.4458   \n",
       "\n",
       "            BC_Europe    BC_SWI     BC_UK    BC_USA  stock_price  \\\n",
       "2018-10-01   100.9295  102.0386  102.0568  101.2177        91.70   \n",
       "2018-11-01   100.9174  101.8399  102.2486  101.0049        92.31   \n",
       "2018-12-01   100.8464  101.6098  102.3394  100.6920        87.78   \n",
       "\n",
       "            stock_price_change  stock_volume  \n",
       "2018-10-01               -7.81    61460000.0  \n",
       "2018-11-01                0.67    48250000.0  \n",
       "2018-12-01               -4.90    48710000.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f54e5d",
   "metadata": {},
   "source": [
    "**Train-Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4430cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:30.013435Z",
     "start_time": "2025-03-26T09:14:30.008580Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_1, X_val_1, y_train_1, y_val_1 = m.train_val_split(df_1, '#1', val_percentage = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cb759",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cad259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:14:30.675511Z",
     "start_time": "2025-03-26T09:14:30.665757Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_1_scaled, X_val_1_scaled = m.scale_data(X_train_1, \n",
    "                                          X_val_1, \n",
    "                                          scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e30c99",
   "metadata": {},
   "source": [
    "## 2.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c463d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:29:43.974670Z",
     "start_time": "2025-03-26T09:29:43.966864Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFdr, f_regression, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def feature_selection(X_train, y_train, method='all', alpha_ = None,\n",
    "                      rfe_model=None, corr_threshold=0.85, \n",
    "                      importance_threshold='mean', lasso_cv=True):\n",
    "    selected_features = []\n",
    "\n",
    "    if method == 'correlation':\n",
    "        corr_matrix = X_train.corr()\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        correlated_features = [column for column in upper_triangle.columns if any(upper_triangle[column].abs() > corr_threshold)]\n",
    "        selected_features = [col for col in X_train.columns if col not in correlated_features]\n",
    "        print(f'Selected {len(selected_features)} features by correlation')\n",
    "\n",
    "    elif method == 'univariate':\n",
    "        selector = SelectFdr(score_func=f_regression, alpha = alpha_)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[selector.get_support()]\n",
    "        print(f'Selected {len(selected_features)} features by univariate selection (p < {alpha_})')\n",
    "\n",
    "    elif method == 'rfe':\n",
    "        if rfe_model is None:\n",
    "            rfe_model = LinearRegression()\n",
    "            \n",
    "        rfecv = RFECV(estimator=rfe_model, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        rfecv.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfecv.support_]\n",
    "        print(f'Selected {len(selected_features)} features by RFECV')\n",
    "\n",
    "    elif method == 'importance':\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        if importance_threshold == 'mean':\n",
    "            threshold_value = np.mean(importances)\n",
    "        elif importance_threshold == 'median':\n",
    "            threshold_value = np.median(importances)\n",
    "        else:\n",
    "            threshold_value = float(importance_threshold)\n",
    "\n",
    "        selected_features = X_train.columns[importances > threshold_value]\n",
    "        print(f'Selected {len(selected_features)} features by importance with threshold {threshold_value}')\n",
    "\n",
    "    elif method == 'lasso':\n",
    "        lasso = LassoCV(cv=5, random_state=42).fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[lasso.coef_ != 0].tolist()\n",
    "        print(f'Selected {len(selected_features)} features by Lasso regularization')\n",
    "\n",
    "    elif method == 'all':\n",
    "        corr_features = feature_selection(X_train, y_train, method='correlation', corr_threshold=corr_threshold)\n",
    "        univariate_features = feature_selection(X_train, y_train, method='univariate', alpha_ = alpha_)\n",
    "        rfe_features = feature_selection(X_train, y_train, method='rfe', rfe_model=rfe_model)\n",
    "        importance_features = feature_selection(X_train, y_train, method='importance', importance_threshold=importance_threshold)\n",
    "        lasso_features = feature_selection(X_train, y_train, method='lasso')\n",
    "\n",
    "        selected_features = list(set(corr_features) & set(univariate_features) & set(rfe_features) & set(importance_features) & set(lasso_features))\n",
    "        print(f'Selected {len(selected_features)} features that intersect across all methods')\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0686a3b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:31:32.885240Z",
     "start_time": "2025-03-26T09:30:21.592799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 25 features by correlation\n",
      "Selected 18 features by univariate selection (p < 0.6)\n",
      "Selected 16 features by RFECV\n",
      "Selected 26 features by importance with threshold 0.008695652173913044\n",
      "Selected 5 features by Lasso regularization\n",
      "Selected 2 features that intersect across all methods\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['USA Shipments Index_Rolling_Mean_3', 'UK EE Production Index_Rolling_Mean_3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = feature_selection(X_train_1_scaled, y_train_1, \n",
    "                                      method='all', \n",
    "                                      alpha_ = 0.6,\n",
    "                                      rfe_model = XGBRegressor(), \n",
    "                                      corr_threshold=0.85, \n",
    "                                      importance_threshold = 'mean')\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b75280f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:24:13.030112Z",
     "start_time": "2025-03-26T09:24:10.638036Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet import Prophet  # Prophet model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.arima.model import ARIMA  # ARIMA model\n",
    "\n",
    "def modelling(X_train, y_train, X_test, y_test, \n",
    "              features_used, \n",
    "              metric='RMSE', \n",
    "              model_choice='arima', \n",
    "              save_path='./modelling_csvs/results.csv'):\n",
    "\n",
    "\n",
    "    # If ARIMA is chosen\n",
    "    if model_choice == 'arima':\n",
    "        if len(features_used) > 1:\n",
    "            raise ValueError('ARIMA only accepts 1 feature for the target variable.')\n",
    "        model = ARIMA(y_train, order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Predict\n",
    "        predictions = model_fit.forecast(len(y_test))\n",
    "        \n",
    "        # Calculate RMSE or any other metric\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        best_model_name = 'ARIMA'\n",
    "        best_score = rmse\n",
    "        print(f'ARIMA RMSE: {rmse}')\n",
    "\n",
    "    # Initialize LazyRegressor if 'lazy' model is chosen\n",
    "    elif model_choice == 'lazy':\n",
    "        regressor = LazyRegressor(verbose=0)\n",
    "        models, predictions = regressor.fit(X_train[features_used], X_test[features_used], y_train, y_test)\n",
    "        \n",
    "        # Select the best model based on the metric\n",
    "        best_model = models.sort_values(by=metric).iloc[0]\n",
    "        best_model_name = best_model.name\n",
    "        best_score = best_model[metric]\n",
    "        print(f'Best model: {best_model_name}')\n",
    "        print(f'{metric} of the best model: {best_score}')\n",
    "    \n",
    "    # If Prophet is chosen\n",
    "    elif model_choice == 'prophet':\n",
    "        raise ValueError('NOT WORKING YET')\n",
    "        # Initialize an empty DataFrame to hold future feature values\n",
    "        future_features = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each column in 'features_used'\n",
    "        for column in features_used:\n",
    "            # Isolate the current column into a new DataFrame 'df1'\n",
    "            df1 = X_train[[column]].copy()\n",
    "\n",
    "            # Reset the index of 'df1' and rename columns to fit Prophet's expected format\n",
    "            data = (df1.reset_index()\n",
    "                    .rename(columns={'index': 'ds', f'{column}': 'y'}))\n",
    "\n",
    "            # Initialize Prophet model\n",
    "            model = Prophet()\n",
    "\n",
    "            # Fit the model to the data\n",
    "            model.fit(data)\n",
    "\n",
    "            # Create a DataFrame representing future dates to make predictions\n",
    "            future = model.make_future_dataframe(periods=10, freq='MS')\n",
    "\n",
    "            # Forecast future dates\n",
    "            forecast_index = model.predict(future)\n",
    "\n",
    "            forecast_index = forecast_index[['ds', 'yhat']]\n",
    "            \n",
    "            # Set the date column as the index\n",
    "            forecast_index = forecast_index.set_index('ds')\n",
    "\n",
    "            # Add the forecasted values to the 'future_features' DataFrame\n",
    "            future_features[column] = forecast_index['yhat'].values\n",
    "\n",
    "        # Reset the index to use date as a regular column\n",
    "        future_features.reset_index(inplace=True)\n",
    "\n",
    "        # Add the date column to 'future_features'\n",
    "        future_features['ds'] = forecast_index['ds'].values\n",
    "\n",
    "        # Set date as the index of 'future_features'\n",
    "        future_features.set_index('ds', inplace=True)\n",
    "\n",
    "        # For demonstration, using RMSE here:\n",
    "        predicted_values = future_features[features_used].mean(axis=1)  # For simplicity, take the mean of all predictions\n",
    "        rmse = mean_squared_error(y_test, predicted_values, squared=False)\n",
    "        \n",
    "        # Compare RMSE to get best model\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_model_name = 'prophet'\n",
    "            \n",
    "    # Prepare row to save\n",
    "    result_row = {\n",
    "        'Features Used': ', '.join(features_used),\n",
    "        'Best Model': best_model_name,\n",
    "        metric: best_score\n",
    "    }\n",
    "    \n",
    "    # Check if file exists; if not, create with headers\n",
    "    if not os.path.isfile(save_path):\n",
    "        results_df = pd.DataFrame([result_row])\n",
    "        results_df.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        # Append without overwriting\n",
    "        results_df = pd.DataFrame([result_row])\n",
    "        results_df.to_csv(save_path, mode='a', header=False, index=False)\n",
    "    \n",
    "    return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "341ece87-c8ad-4b56-ba7f-ad5cdbd6260b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NOT WORKING YET",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_model_name, best_score  = \u001b[43mmodelling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_1_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m              \u001b[49m\u001b[43mfeatures_used\u001b[49m\u001b[43m=\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m              \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRMSE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m              \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprophet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mmodelling\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, features_used, metric, model_choice, save_path)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# If Prophet is chosen\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_choice == \u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mNOT WORKING YET\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# Initialize an empty DataFrame to hold future feature values\u001b[39;00m\n\u001b[32m     51\u001b[39m     future_features = pd.DataFrame()\n",
      "\u001b[31mValueError\u001b[39m: NOT WORKING YET"
     ]
    }
   ],
   "source": [
    "best_model_name, best_score  = modelling(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "              features_used=selected_features, \n",
    "              metric='RMSE', \n",
    "              model_choice='prophet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb18eb30-2c80-4ea0-8374-87151d56e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def prophet_forecast(X_train, y_train, features_used, periods=10, freq='MS'):\n",
    "    \"\"\"\n",
    "    Function to perform forecasting using Prophet for each feature in 'features_used'.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: DataFrame containing the training data\n",
    "    - y_train: Actual ground truth values for RMSE calculation (training data)\n",
    "    - features_used: List of features/columns to forecast using Prophet\n",
    "    - periods: Number of future periods to predict (default=10)\n",
    "    - freq: Frequency of the periods (default='MS' for monthly start)\n",
    "\n",
    "    Returns:\n",
    "    - best_model_name: Name of the best model ('prophet')\n",
    "    - best_score: The lowest RMSE score for the model\n",
    "    \"\"\"\n",
    "    best_score = float('inf')\n",
    "    best_model_name = None\n",
    "\n",
    "    # Initialize an empty DataFrame to hold future feature values\n",
    "    future_features = pd.DataFrame()\n",
    "\n",
    "    # Iterate through each column in 'features_used'\n",
    "    for column in features_used:\n",
    "        # Isolate the current column into a new DataFrame 'df1'\n",
    "        df1 = X_train[[column]].copy()\n",
    "\n",
    "        # Reset the index of 'df1' and rename columns to fit Prophet's expected format\n",
    "        data = (df1.reset_index()\n",
    "                .rename(columns={'index': 'ds', f'{column}': 'y'}))\n",
    "\n",
    "        # Initialize Prophet model\n",
    "        model = Prophet()\n",
    "\n",
    "        # Fit the model to the data\n",
    "        model.fit(data)\n",
    "\n",
    "        # Create a DataFrame representing future dates to make predictions\n",
    "        future = model.make_future_dataframe(periods=periods, freq=freq)\n",
    "\n",
    "        # Forecast future dates\n",
    "        forecast_index = model.predict(future)\n",
    "\n",
    "        # Select relevant columns ('ds' for date, 'yhat' for predictions)\n",
    "        forecast_index = forecast_index[['ds', 'yhat']]\n",
    "\n",
    "        # Set the date column as the index\n",
    "        forecast_index = forecast_index.set_index('ds')\n",
    "\n",
    "        # Add the forecasted values to the 'future_features' DataFrame\n",
    "        future_features[column] = forecast_index['yhat'].values\n",
    "\n",
    "    # Reset the index of the future_features DataFrame to use 'ds' as a regular column\n",
    "    future_features.reset_index(inplace=True)\n",
    "\n",
    "    # Add the date column to 'future_features'\n",
    "    future_features['ds'] = forecast_index.index.values\n",
    "\n",
    "    # Set 'ds' as the index of 'future_features'\n",
    "    future_features.set_index('ds', inplace=True)\n",
    "\n",
    "    # Ensure we only compare the forecasted values against a valid subset of y_train\n",
    "    # For simplicity, we will compare the mean of the forecasted values to the corresponding `y_train` values\n",
    "    predicted_values = future_features[features_used].mean(axis=1)  # For simplicity, take the mean of all predictions\n",
    "\n",
    "    rmse = mean_squared_error(y_train, predicted_values)\n",
    "\n",
    "    # Compare RMSE to get the best model\n",
    "    if rmse < best_score:\n",
    "        best_score = rmse\n",
    "        best_model_name = 'prophet'\n",
    "\n",
    "    return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b5d595e-afad-4036-9532-7170a4592007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:44:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:44:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31, 41]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprophet_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mprophet_forecast\u001b[39m\u001b[34m(X_train, y_train, features_used, periods, freq)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Ensure we only compare the forecasted values against a valid subset of y_train\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# For simplicity, we will compare the mean of the forecasted values to the corresponding `y_train` values\u001b[39;00m\n\u001b[32m     67\u001b[39m predicted_values = future_features[features_used].mean(axis=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# For simplicity, take the mean of all predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Compare RMSE to get the best model\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rmse < best_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:565\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    516\u001b[39m \n\u001b[32m    517\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    561\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    563\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    564\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m )\n\u001b[32m    569\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    570\u001b[39m output_errors = _average((y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:198\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03mregression task.\u001b[39;00m\n\u001b[32m    150\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m y_type, y_true, y_pred, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/metrics/_regression.py:104\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, multioutput, dtype, xp)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    106\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [31, 41]"
     ]
    }
   ],
   "source": [
    "prophet_forecast(X_train_1_scaled, y_train_1, selected_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd585af-d3c1-40a5-8034-45d5b0d76496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cd7e059-cb3c-436a-a042-c3061d431445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.14.4-cp313-cp313-macosx_10_13_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (2.2.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (1.15.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Using cached statsmodels-0.14.4-cp313-cp313-macosx_10_13_x86_64.whl (10.2 MB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "855ac6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:42:17.540624Z",
     "start_time": "2025-03-25T10:42:16.316552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:01<00:00, 34.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 36289610.258065\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best model: SVR\n",
      "RMSE of the best model: 2887703.8751545465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_1_selected = X_train_1_scaled[selected_features]\n",
    "X_val_1_selected = X_val_1_scaled[selected_features]\n",
    "\n",
    "best_model_name, best_score = modelling(\n",
    "    X_train_1_selected, y_train_1, X_val_1_selected, y_val_1, \n",
    "    features_used=selected_features, metric='RMSE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18f4288a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:53:41.960098Z",
     "start_time": "2025-03-23T15:53:41.955735Z"
    }
   },
   "outputs": [],
   "source": [
    "# import lazypredict\n",
    "# from lazypredict.Supervised import LazyRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# def lazy_regressor(X_train, y_train, X_test, y_test, metric='RMSE'):\n",
    "    \n",
    "#     # Initialize LazyRegressor\n",
    "#     regressor = LazyRegressor(verbose=0)\n",
    "    \n",
    "#     # Fit the model\n",
    "#     models, predictions = regressor.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "#     # Select the best model based on the metric (e.g., RMSE)\n",
    "#     best_model = models.sort_values(by=metric).iloc[0]\n",
    "    \n",
    "#     # Get the model name and the best score\n",
    "#     best_model_name = best_model.name\n",
    "#     best_score = best_model[metric]\n",
    "    \n",
    "#     print(f'Best model: {best_model_name}')\n",
    "#     print(f'{metric} of the best model: {best_score}')\n",
    "    \n",
    "#     # Return the best model and score\n",
    "#     return best_model_name, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9110ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:53:44.734147Z",
     "start_time": "2025-03-23T15:53:42.340731Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:02<00:00, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 36289610.258065\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Best model: GradientBoostingRegressor\n",
      "RMSE of the best model: 2847141.438462039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# best_model_name, best_score = lazy_regressor(X_train_1_scaled, y_train_1,\n",
    "#                                              X_val_1_scaled, y_val_1,\n",
    "#                                              metric='RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cf56a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:42:19.884930Z",
     "start_time": "2025-03-25T10:42:19.877181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(W) Price of Base Metals, GER Production Index...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA Shipments Index_Rolling_Mean_3</td>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>2823366.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BC_CHI, USA Shipments Index_Rolling_Mean_3, CH...</td>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>2830173.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(W) Price of Base Metals, GER Production Index...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(W) Price of Natural gas index, USA Production...</td>\n",
       "      <td>SVR</td>\n",
       "      <td>2887703.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Features Used      Best Model  \\\n",
       "0  (W) Price of Base Metals, GER Production Index...             SVR   \n",
       "1                 USA Shipments Index_Rolling_Mean_3  HuberRegressor   \n",
       "2  BC_CHI, USA Shipments Index_Rolling_Mean_3, CH...  HuberRegressor   \n",
       "3  (W) Price of Base Metals, GER Production Index...             SVR   \n",
       "4  (W) Price of Natural gas index, USA Production...             SVR   \n",
       "\n",
       "        RMSE  \n",
       "0 2887703.96  \n",
       "1 2823366.38  \n",
       "2 2830173.62  \n",
       "3 2887703.92  \n",
       "4 2887703.88  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('./lazy_regressor_results.csv')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85584d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:02:28.834869Z",
     "start_time": "2025-03-23T16:02:28.801224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautosklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maskl2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterAutoregMultiSeries\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "from autosklearn.experimental.askl2 import ForecasterAutoregMultiSeries\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def time_series_forecasting(X_train, y_train, X_test, y_test, \n",
    "                            forecast_steps=10, metric='neg_root_mean_squared_error'):\n",
    "\n",
    "    # Initialize ForecasterAutoregMultiSeries\n",
    "    forecaster = ForecasterAutoregMultiSeries(steps=forecast_steps, metric=metric)\n",
    "    \n",
    "    # Fit the forecaster with training data\n",
    "    forecaster.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = forecaster.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'Test RMSE: {rmse}')\n",
    "    \n",
    "    return forecaster, y_pred, rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633116",
   "metadata": {},
   "source": [
    "### 2.1.1 Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b2ec6",
   "metadata": {},
   "source": [
    "**Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bec66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.216711Z",
     "start_time": "2025-03-23T15:11:56.216700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_1_scaled.var() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5dced",
   "metadata": {},
   "source": [
    "**Spearman Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e397f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.218093Z",
     "start_time": "2025-03-23T15:11:56.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_matrix(X, cmap='YlOrBr', font_size = 5):\n",
    "    \"\"\"\n",
    "    Input: X (numerical data)\n",
    "    Output: Correlation Matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Plot Heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": font_size})\n",
    "    plt.title(\"Feature Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379196d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.219727Z",
     "start_time": "2025-03-23T15:11:56.219713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5e958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.220921Z",
     "start_time": "2025-03-23T15:11:56.220910Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_correlated_features(X, top_n=20, cmap='YlOrBr'):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    mean_corr = corr_matrix.mean().sort_values(ascending=False)\n",
    "    top_features = mean_corr.head(top_n).index\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(X[top_features].corr(), annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": 8})\n",
    "    plt.title(f\"Top {top_n} Most Correlated Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365f2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.222515Z",
     "start_time": "2025-03-23T15:11:56.222501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_correlated_features(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80988409",
   "metadata": {},
   "source": [
    "### 2.2.2 Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed569a6",
   "metadata": {},
   "source": [
    "**RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f909060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.224068Z",
     "start_time": "2025-03-23T15:11:56.224057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def rfe(X_train, y_train, X_val, y_val, n_features, model=None):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X_train, y_train, X_val, y_val: training and validation data\n",
    "        n_features: number of features to use for RFE\n",
    "        model: chosen regression model \n",
    "    Output: selected features for the best model based on RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    best_rmse = np.inf  # Start with a very high RMSE (lower is better)\n",
    "    best_features = []\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for feature in n_features:\n",
    "        \n",
    "        # Fit RFE\n",
    "        rfe = RFE(estimator=model, n_features_to_select=feature)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        # Get selected features\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "        \n",
    "        print('\\n-------------TRAIN-------------')\n",
    "\n",
    "        # Predictions for Train\n",
    "        y_pred_train = rfe.predict(X_train)\n",
    "        \n",
    "        # Metrics for Training (RMSE)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Train): {rmse_train:.4f}\")\n",
    "        \n",
    "        print('----------VALIDATION----------')\n",
    "\n",
    "        # Predictions for Validation\n",
    "        y_pred_val = rfe.predict(X_val)\n",
    "        \n",
    "        # Metrics for Validation (RMSE)\n",
    "        mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "        rmse_val = np.sqrt(mse_val)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Validation): {rmse_val:.4f}\")\n",
    "        \n",
    "        # Best score based on RMSE (lower is better)\n",
    "        if rmse_val < best_rmse:\n",
    "            best_rmse = rmse_val\n",
    "            best_features = selected_features.tolist()  \n",
    "        \n",
    "    print('\\n----------FINAL----------')\n",
    "    print(f'Best RMSE: {best_rmse}')\n",
    "    print(f'Number of Features: {len(best_features)}')\n",
    "    print(f'Features: {best_features}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.225027Z",
     "start_time": "2025-03-23T15:11:56.225016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = LinearRegression()\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.226165Z",
     "start_time": "2025-03-23T15:11:56.226154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = XGBRegressor(objective='reg:squarederror',\n",
    "                     random_state = 100)\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954c798",
   "metadata": {},
   "source": [
    "### 2.2.3 Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3119f7",
   "metadata": {},
   "source": [
    "**LASSO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbeb421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.227721Z",
     "start_time": "2025-03-23T15:11:56.227707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import functions as f\n",
    "def lasso(X, y, alpha = 0.01, color = f.main_color):\n",
    "\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X, y: data\n",
    "        alpha: parameter for lasso\n",
    "    Output: Plot, initial and selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    # Get Feature Importance\n",
    "    importance = pd.Series(lasso.coef_, index=X.columns)\n",
    "    importance.sort_values().plot(kind=\"barh\", color=color)\n",
    "    non_zero_importance = importance[importance != 0]\n",
    "    selected_features = non_zero_importance.index\n",
    "\n",
    "    # Plot\n",
    "    plt.title(\"Lasso Feature Importance\")\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Results\n",
    "    print(f\"\\nInitial Features: {len(X.columns)}\\n\")\n",
    "    print(X.columns.tolist())\n",
    "    print(f\"\\nDecision for Numerical Features (lasso ‚â† 0): {len(selected_features.tolist())}\\n\")\n",
    "    print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614a16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.228825Z",
     "start_time": "2025-03-23T15:11:56.228814Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso(X_train_1_scaled, y_train_1, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969aaa2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a97773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.230110Z",
     "start_time": "2025-03-23T15:11:56.230099Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(X_train_1_scaled, y_train_1)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val_1 = model.predict(X_val_1_scaled)\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse_val_1 = np.sqrt(mean_squared_error(y_val_1, y_pred_val_1))\n",
    "print(f'Root Mean Squared Error on Validation Set: {rmse_val_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e9ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.231315Z",
     "start_time": "2025-03-23T15:11:56.231303Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(y_val_1.index, y_val_1, label='Actual Validation Values', linestyle='-', color='g')\n",
    "plt.plot(y_val_1.index, y_pred_val_1, label='Predicted Validation Values', linestyle='--', color='g')\n",
    "\n",
    "plt.plot(y_train_1.index, y_train_1, label='Actual Training Values', linestyle='-', color='b')\n",
    "\n",
    "plt.xlabel('Date/Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('XGBoost Forecasting: Actual vs Predicted (Training and Validation)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
