{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754c99df",
   "metadata": {},
   "source": [
    "# <p align=\"center\">Siemens Sales Forecast</p>\n",
    "\n",
    "---\n",
    "\n",
    "## <p align=\"center\">*2 - Feature Selection & Modeling*</p>\n",
    "\n",
    "---\n",
    "\n",
    "### üë• **Team Members**\n",
    "- **Ana Farinha** *(Student Number: 20211514)*  \n",
    "- **Ant√≥nio Oliveira** *(Student Number: 20211595)*  \n",
    "- **Mariana Neto** *(Student Number: 20211527)*  \n",
    "- **Salvador Domingues** *(Student Number: 20240597)*  \n",
    "\n",
    "üìÖ **Date:** *April 1, 2025*  \n",
    "üìç **Prepared for:** *Siemens*  \n",
    "\n",
    "**GitHub Repo:** https://github.com/MGN19/Siemens-forecast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217ae9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:48:52.933704Z",
     "start_time": "2025-03-14T14:48:52.929415Z"
    }
   },
   "source": [
    "# ToC\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "1. [Import Libraries & Data](#1.-Import-Libraries-&-Data) <br><br>\n",
    "\n",
    "2. [Product Category #1](#Product-Category-#1) <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6957c6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:53.524977Z",
     "start_time": "2025-03-23T15:11:53.522506Z"
    }
   },
   "outputs": [],
   "source": [
    "## CELL TYPES (remover depois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea5f62",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3ea15",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b453a2e",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9202c2",
   "metadata": {},
   "source": [
    "# 1. Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9d458a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:54.060194Z",
     "start_time": "2025-03-23T15:11:53.527186Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd9fc0",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34b24fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:54.124031Z",
     "start_time": "2025-03-23T15:11:54.063347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_8_diff', 'df_14', 'df_16', 'df_12', 'df_13', 'df_9', 'df_11', 'df_8', 'df_5', 'df_20', 'df_4', 'df_36', 'df_6', 'df_3', 'df_1']\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/individual_dfs/'\n",
    "\n",
    "# List to store the names of each dataframe\n",
    "imported_df_names = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        df_name = file.replace('.csv', '')  # Get name without .csv\n",
    "        df_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read CSV and assign to a variable\n",
    "        globals()[df_name] = pd.read_csv(df_path, index_col=0)\n",
    "        \n",
    "        # Store the dataframe name in the list\n",
    "        imported_df_names.append(df_name)\n",
    "\n",
    "# Convert the index of all DataFrames to datetime\n",
    "for df_name in imported_df_names:\n",
    "    globals()[df_name].index = pd.to_datetime(globals()[df_name].index)\n",
    "\n",
    "# Optional: print to check\n",
    "print(imported_df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998ca9d",
   "metadata": {},
   "source": [
    "# Product Category #1\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6247af78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:27:01.466786Z",
     "start_time": "2025-03-23T15:27:01.460812Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#1                                  0\n",
       "CHI Production Index                0\n",
       "CHI Shipments Index                 0\n",
       "FRA Production Index                0\n",
       "FRA Shipments Index                 0\n",
       "GER Production Index                0\n",
       "GER Shipments Index                 0\n",
       "ITA Production Index                0\n",
       "ITA Shipments Index                 0\n",
       "JAP Production Index                0\n",
       "JAP Shipments Index                 0\n",
       "SWI Production Index                1\n",
       "SWI Shipments Index                 1\n",
       "UK Production Index                 0\n",
       "UK Shipments Index                 18\n",
       "USA Production Index                0\n",
       "USA Shipments Index                 1\n",
       "Europe Production Index             0\n",
       "Europe Shipments Index              0\n",
       "(W) Price of Base Metals            0\n",
       "(W) Price of Energy                 0\n",
       "(W) Price of Metals & Minerals      0\n",
       "(W) Price of Natural gas index      0\n",
       "(W) Price of Crude oil, average     0\n",
       "(W) Price of Copper                 0\n",
       "USA EUR to LCU Conversion Rate      0\n",
       "USA EE Producer Prices              0\n",
       "UK EE Producer Prices              18\n",
       "ITA EE Producer Prices              0\n",
       "FRA EE Producer Prices              0\n",
       "GER EE Producer Prices              0\n",
       "CHI EE Producer Prices              0\n",
       "USA Machinery & Equipment Index     0\n",
       "(W) Machinery & Equipment Index     0\n",
       "SWI Machinery & Equipment Index     1\n",
       "UK Machinery & Equipment Index      0\n",
       "ITA Machinery & Equipment Index     0\n",
       "JAP Machinery & Equipment Index     0\n",
       "FRA Machinery & Equipment Index     0\n",
       "GER Machinery & Equipment Index     0\n",
       "USA EE Production Index             0\n",
       "(W) EE Production Index             0\n",
       "SWI EE Production Index             1\n",
       "UK EE Production Index              0\n",
       "ITA EE Production Index             0\n",
       "JAP EE Production Index             0\n",
       "FRA EE Production Index             0\n",
       "GER EE Production Index             0\n",
       "CC_CHI                              0\n",
       "CC_FRA                              0\n",
       "CC_GER                              0\n",
       "CC_ITA                              0\n",
       "CC_JAP                              0\n",
       "CC_Europe                           0\n",
       "CC_SWI                              0\n",
       "CC_UK                               0\n",
       "CC_USA                              0\n",
       "BC_CHI                              0\n",
       "BC_FRA                              0\n",
       "BC_GER                              0\n",
       "BC_ITA                              0\n",
       "BC_JAP                              0\n",
       "BC_Europe                           0\n",
       "BC_SWI                              0\n",
       "BC_UK                               0\n",
       "BC_USA                              0\n",
       "stock_price                         0\n",
       "stock_price_change                  0\n",
       "stock_volume                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e78bb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:14:49.977323Z",
     "start_time": "2025-03-23T15:14:49.941483Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1</th>\n",
       "      <th>CHI Production Index</th>\n",
       "      <th>CHI Shipments Index</th>\n",
       "      <th>FRA Production Index</th>\n",
       "      <th>FRA Shipments Index</th>\n",
       "      <th>GER Production Index</th>\n",
       "      <th>GER Shipments Index</th>\n",
       "      <th>ITA Production Index</th>\n",
       "      <th>ITA Shipments Index</th>\n",
       "      <th>JAP Production Index</th>\n",
       "      <th>JAP Shipments Index</th>\n",
       "      <th>SWI Production Index</th>\n",
       "      <th>SWI Shipments Index</th>\n",
       "      <th>UK Production Index</th>\n",
       "      <th>UK Shipments Index</th>\n",
       "      <th>USA Production Index</th>\n",
       "      <th>USA Shipments Index</th>\n",
       "      <th>Europe Production Index</th>\n",
       "      <th>Europe Shipments Index</th>\n",
       "      <th>(W) Price of Base Metals</th>\n",
       "      <th>(W) Price of Energy</th>\n",
       "      <th>(W) Price of Metals &amp; Minerals</th>\n",
       "      <th>(W) Price of Natural gas index</th>\n",
       "      <th>(W) Price of Crude oil, average</th>\n",
       "      <th>(W) Price of Copper</th>\n",
       "      <th>USA EUR to LCU Conversion Rate</th>\n",
       "      <th>USA EE Producer Prices</th>\n",
       "      <th>UK EE Producer Prices</th>\n",
       "      <th>ITA EE Producer Prices</th>\n",
       "      <th>FRA EE Producer Prices</th>\n",
       "      <th>GER EE Producer Prices</th>\n",
       "      <th>CHI EE Producer Prices</th>\n",
       "      <th>USA Machinery &amp; Equipment Index</th>\n",
       "      <th>(W) Machinery &amp; Equipment Index</th>\n",
       "      <th>SWI Machinery &amp; Equipment Index</th>\n",
       "      <th>UK Machinery &amp; Equipment Index</th>\n",
       "      <th>ITA Machinery &amp; Equipment Index</th>\n",
       "      <th>JAP Machinery &amp; Equipment Index</th>\n",
       "      <th>FRA Machinery &amp; Equipment Index</th>\n",
       "      <th>GER Machinery &amp; Equipment Index</th>\n",
       "      <th>USA EE Production Index</th>\n",
       "      <th>(W) EE Production Index</th>\n",
       "      <th>SWI EE Production Index</th>\n",
       "      <th>UK EE Production Index</th>\n",
       "      <th>ITA EE Production Index</th>\n",
       "      <th>JAP EE Production Index</th>\n",
       "      <th>FRA EE Production Index</th>\n",
       "      <th>GER EE Production Index</th>\n",
       "      <th>CC_CHI</th>\n",
       "      <th>CC_FRA</th>\n",
       "      <th>CC_GER</th>\n",
       "      <th>CC_ITA</th>\n",
       "      <th>CC_JAP</th>\n",
       "      <th>CC_Europe</th>\n",
       "      <th>CC_SWI</th>\n",
       "      <th>CC_UK</th>\n",
       "      <th>CC_USA</th>\n",
       "      <th>BC_CHI</th>\n",
       "      <th>BC_FRA</th>\n",
       "      <th>BC_GER</th>\n",
       "      <th>BC_ITA</th>\n",
       "      <th>BC_JAP</th>\n",
       "      <th>BC_Europe</th>\n",
       "      <th>BC_SWI</th>\n",
       "      <th>BC_UK</th>\n",
       "      <th>BC_USA</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>stock_price_change</th>\n",
       "      <th>stock_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>36098918.79</td>\n",
       "      <td>211.955755</td>\n",
       "      <td>211.955755</td>\n",
       "      <td>108.280608</td>\n",
       "      <td>122.451734</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>137.741953</td>\n",
       "      <td>118.350514</td>\n",
       "      <td>122.456894</td>\n",
       "      <td>125.209957</td>\n",
       "      <td>124.793250</td>\n",
       "      <td>109.077781</td>\n",
       "      <td>104.594781</td>\n",
       "      <td>113.659322</td>\n",
       "      <td>112.318030</td>\n",
       "      <td>111.902540</td>\n",
       "      <td>127.808839</td>\n",
       "      <td>124.391967</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>86.102586</td>\n",
       "      <td>100.222169</td>\n",
       "      <td>79.354986</td>\n",
       "      <td>89.570796</td>\n",
       "      <td>97.072264</td>\n",
       "      <td>82.545082</td>\n",
       "      <td>1.1484</td>\n",
       "      <td>110.700409</td>\n",
       "      <td>111.463669</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.064743</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>96.318329</td>\n",
       "      <td>111.422638</td>\n",
       "      <td>131.340118</td>\n",
       "      <td>106.816937</td>\n",
       "      <td>110.893450</td>\n",
       "      <td>129.389221</td>\n",
       "      <td>131.503786</td>\n",
       "      <td>114.720810</td>\n",
       "      <td>127.461136</td>\n",
       "      <td>112.853256</td>\n",
       "      <td>129.325775</td>\n",
       "      <td>112.970843</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>93.001511</td>\n",
       "      <td>112.376774</td>\n",
       "      <td>97.849541</td>\n",
       "      <td>118.298233</td>\n",
       "      <td>102.8056</td>\n",
       "      <td>98.94864</td>\n",
       "      <td>101.5778</td>\n",
       "      <td>101.7588</td>\n",
       "      <td>100.3849</td>\n",
       "      <td>100.7815</td>\n",
       "      <td>100.3180</td>\n",
       "      <td>100.6982</td>\n",
       "      <td>101.5022</td>\n",
       "      <td>98.79642</td>\n",
       "      <td>101.0451</td>\n",
       "      <td>101.7476</td>\n",
       "      <td>100.9696</td>\n",
       "      <td>101.5259</td>\n",
       "      <td>100.9295</td>\n",
       "      <td>102.0386</td>\n",
       "      <td>102.0568</td>\n",
       "      <td>101.2177</td>\n",
       "      <td>91.70</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>61460000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>37323903.07</td>\n",
       "      <td>220.519655</td>\n",
       "      <td>220.519655</td>\n",
       "      <td>99.636911</td>\n",
       "      <td>115.958210</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>142.732193</td>\n",
       "      <td>107.719260</td>\n",
       "      <td>120.132032</td>\n",
       "      <td>122.624695</td>\n",
       "      <td>123.289888</td>\n",
       "      <td>112.241491</td>\n",
       "      <td>107.656238</td>\n",
       "      <td>115.088417</td>\n",
       "      <td>112.801011</td>\n",
       "      <td>110.880401</td>\n",
       "      <td>117.675874</td>\n",
       "      <td>123.070091</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>83.841374</td>\n",
       "      <td>84.436807</td>\n",
       "      <td>77.500875</td>\n",
       "      <td>97.362468</td>\n",
       "      <td>78.841167</td>\n",
       "      <td>82.230939</td>\n",
       "      <td>1.1367</td>\n",
       "      <td>110.994026</td>\n",
       "      <td>111.668373</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.064743</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>95.370118</td>\n",
       "      <td>109.737129</td>\n",
       "      <td>129.976456</td>\n",
       "      <td>110.792831</td>\n",
       "      <td>112.119922</td>\n",
       "      <td>117.990173</td>\n",
       "      <td>127.880755</td>\n",
       "      <td>104.873100</td>\n",
       "      <td>132.987915</td>\n",
       "      <td>113.145294</td>\n",
       "      <td>128.236176</td>\n",
       "      <td>114.736013</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>84.133400</td>\n",
       "      <td>111.907535</td>\n",
       "      <td>91.155960</td>\n",
       "      <td>117.163727</td>\n",
       "      <td>103.2386</td>\n",
       "      <td>98.71818</td>\n",
       "      <td>101.5438</td>\n",
       "      <td>101.6450</td>\n",
       "      <td>100.2850</td>\n",
       "      <td>100.6595</td>\n",
       "      <td>100.3069</td>\n",
       "      <td>100.4390</td>\n",
       "      <td>101.3958</td>\n",
       "      <td>98.45412</td>\n",
       "      <td>100.9598</td>\n",
       "      <td>101.5859</td>\n",
       "      <td>100.8509</td>\n",
       "      <td>101.5088</td>\n",
       "      <td>100.9174</td>\n",
       "      <td>101.8399</td>\n",
       "      <td>102.2486</td>\n",
       "      <td>101.0049</td>\n",
       "      <td>92.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>48250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>37889612.12</td>\n",
       "      <td>241.846854</td>\n",
       "      <td>241.846854</td>\n",
       "      <td>94.690312</td>\n",
       "      <td>115.128469</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>141.407661</td>\n",
       "      <td>88.783181</td>\n",
       "      <td>131.936099</td>\n",
       "      <td>122.991956</td>\n",
       "      <td>124.508413</td>\n",
       "      <td>115.405201</td>\n",
       "      <td>110.717696</td>\n",
       "      <td>101.556108</td>\n",
       "      <td>94.503733</td>\n",
       "      <td>106.257796</td>\n",
       "      <td>123.280134</td>\n",
       "      <td>113.858005</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>82.733389</td>\n",
       "      <td>74.898746</td>\n",
       "      <td>76.071705</td>\n",
       "      <td>94.406578</td>\n",
       "      <td>68.268564</td>\n",
       "      <td>80.630361</td>\n",
       "      <td>1.1384</td>\n",
       "      <td>111.162231</td>\n",
       "      <td>112.794266</td>\n",
       "      <td>105.297836</td>\n",
       "      <td>102.166710</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>94.994885</td>\n",
       "      <td>103.448280</td>\n",
       "      <td>124.202469</td>\n",
       "      <td>114.768725</td>\n",
       "      <td>99.446384</td>\n",
       "      <td>99.191734</td>\n",
       "      <td>128.125679</td>\n",
       "      <td>104.974617</td>\n",
       "      <td>137.363281</td>\n",
       "      <td>111.823624</td>\n",
       "      <td>117.043549</td>\n",
       "      <td>116.501182</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>64.881248</td>\n",
       "      <td>112.524242</td>\n",
       "      <td>78.033028</td>\n",
       "      <td>89.626122</td>\n",
       "      <td>103.6305</td>\n",
       "      <td>98.62968</td>\n",
       "      <td>101.5190</td>\n",
       "      <td>101.4642</td>\n",
       "      <td>100.1741</td>\n",
       "      <td>100.5454</td>\n",
       "      <td>100.1724</td>\n",
       "      <td>100.1360</td>\n",
       "      <td>101.2298</td>\n",
       "      <td>98.18901</td>\n",
       "      <td>100.8520</td>\n",
       "      <td>101.3715</td>\n",
       "      <td>100.7023</td>\n",
       "      <td>101.4458</td>\n",
       "      <td>100.8464</td>\n",
       "      <td>101.6098</td>\n",
       "      <td>102.3394</td>\n",
       "      <td>100.6920</td>\n",
       "      <td>87.78</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>48710000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     #1  CHI Production Index  CHI Shipments Index  \\\n",
       "2018-10-01  36098918.79            211.955755           211.955755   \n",
       "2018-11-01  37323903.07            220.519655           220.519655   \n",
       "2018-12-01  37889612.12            241.846854           241.846854   \n",
       "\n",
       "            FRA Production Index  FRA Shipments Index  GER Production Index  \\\n",
       "2018-10-01            108.280608           122.451734            124.227879   \n",
       "2018-11-01             99.636911           115.958210            127.404132   \n",
       "2018-12-01             94.690312           115.128469            120.518565   \n",
       "\n",
       "            GER Shipments Index  ITA Production Index  ITA Shipments Index  \\\n",
       "2018-10-01           137.741953            118.350514           122.456894   \n",
       "2018-11-01           142.732193            107.719260           120.132032   \n",
       "2018-12-01           141.407661             88.783181           131.936099   \n",
       "\n",
       "            JAP Production Index  JAP Shipments Index  SWI Production Index  \\\n",
       "2018-10-01            125.209957           124.793250            109.077781   \n",
       "2018-11-01            122.624695           123.289888            112.241491   \n",
       "2018-12-01            122.991956           124.508413            115.405201   \n",
       "\n",
       "            SWI Shipments Index  UK Production Index  UK Shipments Index  \\\n",
       "2018-10-01           104.594781           113.659322          112.318030   \n",
       "2018-11-01           107.656238           115.088417          112.801011   \n",
       "2018-12-01           110.717696           101.556108           94.503733   \n",
       "\n",
       "            USA Production Index  USA Shipments Index  \\\n",
       "2018-10-01            111.902540           127.808839   \n",
       "2018-11-01            110.880401           117.675874   \n",
       "2018-12-01            106.257796           123.280134   \n",
       "\n",
       "            Europe Production Index  Europe Shipments Index  \\\n",
       "2018-10-01               124.391967              130.989253   \n",
       "2018-11-01               123.070091              132.934130   \n",
       "2018-12-01               113.858005              131.261348   \n",
       "\n",
       "            (W) Price of Base Metals  (W) Price of Energy  \\\n",
       "2018-10-01                 86.102586           100.222169   \n",
       "2018-11-01                 83.841374            84.436807   \n",
       "2018-12-01                 82.733389            74.898746   \n",
       "\n",
       "            (W) Price of Metals & Minerals  (W) Price of Natural gas index  \\\n",
       "2018-10-01                       79.354986                       89.570796   \n",
       "2018-11-01                       77.500875                       97.362468   \n",
       "2018-12-01                       76.071705                       94.406578   \n",
       "\n",
       "            (W) Price of Crude oil, average  (W) Price of Copper  \\\n",
       "2018-10-01                        97.072264            82.545082   \n",
       "2018-11-01                        78.841167            82.230939   \n",
       "2018-12-01                        68.268564            80.630361   \n",
       "\n",
       "            USA EUR to LCU Conversion Rate   USA EE Producer Prices  \\\n",
       "2018-10-01                           1.1484              110.700409   \n",
       "2018-11-01                           1.1367              110.994026   \n",
       "2018-12-01                           1.1384              111.162231   \n",
       "\n",
       "            UK EE Producer Prices  ITA EE Producer Prices  \\\n",
       "2018-10-01             111.463669              105.297836   \n",
       "2018-11-01             111.668373              105.297836   \n",
       "2018-12-01             112.794266              105.297836   \n",
       "\n",
       "            FRA EE Producer Prices  GER EE Producer Prices  \\\n",
       "2018-10-01              102.064743              109.119614   \n",
       "2018-11-01              102.064743              109.224838   \n",
       "2018-12-01              102.166710              109.330063   \n",
       "\n",
       "            CHI EE Producer Prices  USA Machinery & Equipment Index  \\\n",
       "2018-10-01               96.318329                       111.422638   \n",
       "2018-11-01               95.370118                       109.737129   \n",
       "2018-12-01               94.994885                       103.448280   \n",
       "\n",
       "            (W) Machinery & Equipment Index  SWI Machinery & Equipment Index  \\\n",
       "2018-10-01                       131.340118                       106.816937   \n",
       "2018-11-01                       129.976456                       110.792831   \n",
       "2018-12-01                       124.202469                       114.768725   \n",
       "\n",
       "            UK Machinery & Equipment Index  ITA Machinery & Equipment Index  \\\n",
       "2018-10-01                      110.893450                       129.389221   \n",
       "2018-11-01                      112.119922                       117.990173   \n",
       "2018-12-01                       99.446384                        99.191734   \n",
       "\n",
       "            JAP Machinery & Equipment Index  FRA Machinery & Equipment Index  \\\n",
       "2018-10-01                       131.503786                       114.720810   \n",
       "2018-11-01                       127.880755                       104.873100   \n",
       "2018-12-01                       128.125679                       104.974617   \n",
       "\n",
       "            GER Machinery & Equipment Index  USA EE Production Index  \\\n",
       "2018-10-01                       127.461136               112.853256   \n",
       "2018-11-01                       132.987915               113.145294   \n",
       "2018-12-01                       137.363281               111.823624   \n",
       "\n",
       "            (W) EE Production Index  SWI EE Production Index  \\\n",
       "2018-10-01               129.325775               112.970843   \n",
       "2018-11-01               128.236176               114.736013   \n",
       "2018-12-01               117.043549               116.501182   \n",
       "\n",
       "            UK EE Production Index  ITA EE Production Index  \\\n",
       "2018-10-01              118.670791                93.001511   \n",
       "2018-11-01              120.467019                84.133400   \n",
       "2018-12-01              105.378705                64.881248   \n",
       "\n",
       "            JAP EE Production Index  FRA EE Production Index  \\\n",
       "2018-10-01               112.376774                97.849541   \n",
       "2018-11-01               111.907535                91.155960   \n",
       "2018-12-01               112.524242                78.033028   \n",
       "\n",
       "            GER EE Production Index    CC_CHI    CC_FRA    CC_GER    CC_ITA  \\\n",
       "2018-10-01               118.298233  102.8056  98.94864  101.5778  101.7588   \n",
       "2018-11-01               117.163727  103.2386  98.71818  101.5438  101.6450   \n",
       "2018-12-01                89.626122  103.6305  98.62968  101.5190  101.4642   \n",
       "\n",
       "              CC_JAP  CC_Europe    CC_SWI     CC_UK    CC_USA    BC_CHI  \\\n",
       "2018-10-01  100.3849   100.7815  100.3180  100.6982  101.5022  98.79642   \n",
       "2018-11-01  100.2850   100.6595  100.3069  100.4390  101.3958  98.45412   \n",
       "2018-12-01  100.1741   100.5454  100.1724  100.1360  101.2298  98.18901   \n",
       "\n",
       "              BC_FRA    BC_GER    BC_ITA    BC_JAP  BC_Europe    BC_SWI  \\\n",
       "2018-10-01  101.0451  101.7476  100.9696  101.5259   100.9295  102.0386   \n",
       "2018-11-01  100.9598  101.5859  100.8509  101.5088   100.9174  101.8399   \n",
       "2018-12-01  100.8520  101.3715  100.7023  101.4458   100.8464  101.6098   \n",
       "\n",
       "               BC_UK    BC_USA  stock_price  stock_price_change  stock_volume  \n",
       "2018-10-01  102.0568  101.2177        91.70               -7.81    61460000.0  \n",
       "2018-11-01  102.2486  101.0049        92.31                0.67    48250000.0  \n",
       "2018-12-01  102.3394  100.6920        87.78               -4.90    48710000.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f54e5d",
   "metadata": {},
   "source": [
    "**Train-Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b260bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:19:15.818168Z",
     "start_time": "2025-03-23T15:19:15.813540Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val_split(df, target_col, val_percentage):\n",
    "    \"\"\"\n",
    "    Splits a time series dataframe into training and validation sets based on a percentage of validation data.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The time series dataframe with a DateTime index.\n",
    "        target_col (str): The name of the target column.\n",
    "        val_percentage (float): The percentage of the data to use for validation (between 0 and 1).\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_val, y_train, y_val (pd.DataFrames/Series)\n",
    "    \"\"\"\n",
    "    n_obs = len(df)\n",
    "    val_size = int(n_obs * val_percentage)\n",
    "    split_index = n_obs - val_size\n",
    "    \n",
    "    train = df.iloc[:split_index]\n",
    "    val = df.iloc[split_index:]\n",
    "    \n",
    "    X_train = train.drop(columns=[target_col])\n",
    "    y_train = train[target_col]\n",
    "    \n",
    "    X_val = val.drop(columns=[target_col])\n",
    "    y_val = val[target_col]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f867a333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:19:17.229143Z",
     "start_time": "2025-03-23T15:19:17.224548Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_val_split(df_1, '#1', val_percentage = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cb759",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01984ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:15:58.379908Z",
     "start_time": "2025-03-23T15:15:57.602115Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "def scale_data(X_train, X_val, scaler_type='minmax'):\n",
    "    \"\"\"\n",
    "    Scales the training and validation data using the specified scaler.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): The training features.\n",
    "        X_val (pd.DataFrame): The validation features.\n",
    "        scaler_type (str): The type of scaler to use.\n",
    "    \n",
    "    Returns:\n",
    "        X_train_scaled (pd.DataFrame): Scaled training features.\n",
    "        X_val_scaled (pd.DataFrame): Scaled validation features.\n",
    "    \"\"\"\n",
    "    # Choose scaler based on input\n",
    "    if scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler type. Choose either 'minmax' or 'standard'.\")\n",
    "    \n",
    "    # Fit on training data and transform it\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Transform the validation data using the same scaler\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Convert back to DataFrame to keep column names\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35cad259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:16:31.420076Z",
     "start_time": "2025-03-23T15:16:31.412293Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_1_scaled, X_val_1_scaled = scale_data(X_train_1, \n",
    "                                          X_val_1, \n",
    "                                          scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e30c99",
   "metadata": {},
   "source": [
    "## 2.1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3bfb2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:25:48.212956Z",
     "start_time": "2025-03-23T15:25:48.201720Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def feature_selection(X_train, y_train, method='all', \n",
    "                      k=10, rfe_model=None):\n",
    "    \n",
    "    selected_features = []\n",
    "    \n",
    "    if method == 'correlation':\n",
    "        # Correlation-based Feature Selection\n",
    "        corr_matrix = X_train.corr()\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        correlated_features = [column for column in upper_triangle.columns if any(upper_triangle[column].abs() > 0.9)]\n",
    "        selected_features = [col for col in X_train.columns if col not in correlated_features]\n",
    "        print(f'Removed correlated features: {correlated_features}')\n",
    "    \n",
    "    # Univariate Feature Selection\n",
    "    elif method == 'univariate':\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[selector.get_support()]\n",
    "        print(f'Selected features: {selected_features}')\n",
    "    \n",
    "    # RFE\n",
    "    elif method == 'rfe':\n",
    "        if rfe_model is None:\n",
    "            # Default to Linear Regression if no model is provided\n",
    "            rfe_model = LinearRegression()\n",
    "        \n",
    "        rfe = RFE(rfe_model, n_features_to_select=k)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "        print(f'Selected features using RFE: {selected_features}')\n",
    "    \n",
    "    # Feature Importance\n",
    "    elif method == 'importance':\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        importance = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "        selected_features = feature_importance_df.head(k)['Feature'].tolist()\n",
    "        print(f'Selected features based on importance: {selected_features}')\n",
    "    \n",
    "    # All Methods\n",
    "    elif method == 'all':\n",
    "        corr_features = feature_selection(X_train, y_train, method='correlation', k=k, rfe_model=rfe_model)\n",
    "        univariate_features = feature_selection(X_train, y_train, method='univariate', k=k, rfe_model=rfe_model)\n",
    "        rfe_features = feature_selection(X_train, y_train, method='rfe', k=k, rfe_model=rfe_model)\n",
    "        importance_features = feature_selection(X_train, y_train, method='importance', k=k, rfe_model=rfe_model)\n",
    "        \n",
    "        # Intersect the selected features from all methods\n",
    "        selected_features = list(set(corr_features) & set(univariate_features) & set(rfe_features) & set(importance_features))\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "420b9869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:26:23.752554Z",
     "start_time": "2025-03-23T15:26:23.127220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed correlated features: ['CHI Shipments Index', 'FRA Shipments Index', 'GER Shipments Index', 'ITA Production Index', 'JAP Shipments Index', 'SWI Shipments Index', 'UK Production Index', 'UK Shipments Index', 'Europe Production Index', 'Europe Shipments Index', '(W) Price of Metals & Minerals', '(W) Price of Crude oil, average', '(W) Price of Copper', 'USA EE Producer Prices', 'USA Machinery & Equipment Index', '(W) Machinery & Equipment Index', 'SWI Machinery & Equipment Index', 'UK Machinery & Equipment Index', 'ITA Machinery & Equipment Index', 'JAP Machinery & Equipment Index', 'FRA Machinery & Equipment Index', 'GER Machinery & Equipment Index', 'ITA EE Production Index', 'JAP EE Production Index', 'FRA EE Production Index', 'CC_GER', 'CC_ITA', 'CC_JAP', 'CC_Europe', 'CC_SWI', 'CC_UK', 'CC_USA', 'BC_FRA', 'BC_ITA', 'BC_JAP', 'BC_Europe', 'BC_SWI', 'BC_UK', 'BC_USA', 'stock_price']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_1_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 50\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(X_train, y_train, method, k, rfe_model)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     49\u001b[0m     corr_features \u001b[38;5;241m=\u001b[39m feature_selection(X_train, y_train, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk, rfe_model\u001b[38;5;241m=\u001b[39mrfe_model)\n\u001b[0;32m---> 50\u001b[0m     univariate_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munivariate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfe_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrfe_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     rfe_features \u001b[38;5;241m=\u001b[39m feature_selection(X_train, y_train, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfe\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk, rfe_model\u001b[38;5;241m=\u001b[39mrfe_model)\n\u001b[1;32m     52\u001b[0m     importance_features \u001b[38;5;241m=\u001b[39m feature_selection(X_train, y_train, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk, rfe_model\u001b[38;5;241m=\u001b[39mrfe_model)\n",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m, in \u001b[0;36mfeature_selection\u001b[0;34m(X_train, y_train, method, k, rfe_model)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munivariate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m     selector \u001b[38;5;241m=\u001b[39m SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_classif, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns[selector\u001b[38;5;241m.\u001b[39mget_support()]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelected features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:562\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    560\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[1;32m    567\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Text_Mining/lib/python3.10/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSelectKBest does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "feature_selection(X_train_1_scaled, y_train_1, \n",
    "                  method='all', \n",
    "                  k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633116",
   "metadata": {},
   "source": [
    "### 2.1.1 Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b2ec6",
   "metadata": {},
   "source": [
    "**Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bec66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.216711Z",
     "start_time": "2025-03-23T15:11:56.216700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_1_scaled.var() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5dced",
   "metadata": {},
   "source": [
    "**Spearman Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e397f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.218093Z",
     "start_time": "2025-03-23T15:11:56.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def correlation_matrix(X, cmap='YlOrBr', font_size = 5):\n",
    "    \"\"\"\n",
    "    Input: X (numerical data)\n",
    "    Output: Correlation Matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Plot Heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": font_size})\n",
    "    plt.title(\"Feature Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379196d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.219727Z",
     "start_time": "2025-03-23T15:11:56.219713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5e958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.220921Z",
     "start_time": "2025-03-23T15:11:56.220910Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_correlated_features(X, top_n=20, cmap='YlOrBr'):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    mean_corr = corr_matrix.mean().sort_values(ascending=False)\n",
    "    top_features = mean_corr.head(top_n).index\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(X[top_features].corr(), annot=True, cmap=cmap, fmt=\".2f\", annot_kws={\"size\": 8})\n",
    "    plt.title(f\"Top {top_n} Most Correlated Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365f2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.222515Z",
     "start_time": "2025-03-23T15:11:56.222501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_correlated_features(X_train_1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80988409",
   "metadata": {},
   "source": [
    "### 2.2.2 Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed569a6",
   "metadata": {},
   "source": [
    "**RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f909060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.224068Z",
     "start_time": "2025-03-23T15:11:56.224057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def rfe(X_train, y_train, X_val, y_val, n_features, model=None):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X_train, y_train, X_val, y_val: training and validation data\n",
    "        n_features: number of features to use for RFE\n",
    "        model: chosen regression model \n",
    "    Output: selected features for the best model based on RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    best_rmse = np.inf  # Start with a very high RMSE (lower is better)\n",
    "    best_features = []\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for feature in n_features:\n",
    "        \n",
    "        # Fit RFE\n",
    "        rfe = RFE(estimator=model, n_features_to_select=feature)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        # Get selected features\n",
    "        selected_features = X_train.columns[rfe.support_]\n",
    "        \n",
    "        print('\\n-------------TRAIN-------------')\n",
    "\n",
    "        # Predictions for Train\n",
    "        y_pred_train = rfe.predict(X_train)\n",
    "        \n",
    "        # Metrics for Training (RMSE)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Train): {rmse_train:.4f}\")\n",
    "        \n",
    "        print('----------VALIDATION----------')\n",
    "\n",
    "        # Predictions for Validation\n",
    "        y_pred_val = rfe.predict(X_val)\n",
    "        \n",
    "        # Metrics for Validation (RMSE)\n",
    "        mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "        rmse_val = np.sqrt(mse_val)\n",
    "        \n",
    "        print(f\"RMSE for {feature} features (Validation): {rmse_val:.4f}\")\n",
    "        \n",
    "        # Best score based on RMSE (lower is better)\n",
    "        if rmse_val < best_rmse:\n",
    "            best_rmse = rmse_val\n",
    "            best_features = selected_features.tolist()  \n",
    "        \n",
    "    print('\\n----------FINAL----------')\n",
    "    print(f'Best RMSE: {best_rmse}')\n",
    "    print(f'Number of Features: {len(best_features)}')\n",
    "    print(f'Features: {best_features}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.225027Z",
     "start_time": "2025-03-23T15:11:56.225016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = LinearRegression()\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.226165Z",
     "start_time": "2025-03-23T15:11:56.226154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEMP\n",
    "X_train_1_scaled.fillna(0, inplace = True)\n",
    "X_val_1_scaled.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "n_features = np.arange(1, len(X_train_1_scaled.columns) + 1)\n",
    "model = XGBRegressor(objective='reg:squarederror',\n",
    "                     random_state = 100)\n",
    "\n",
    "rfe(X_train_1_scaled, y_train_1, X_val_1_scaled, y_val_1, \n",
    "                                n_features = n_features, \n",
    "                                model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954c798",
   "metadata": {},
   "source": [
    "### 2.2.3 Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3119f7",
   "metadata": {},
   "source": [
    "**LASSO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbeb421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.227721Z",
     "start_time": "2025-03-23T15:11:56.227707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import functions as f\n",
    "def lasso(X, y, alpha = 0.01, color = f.main_color):\n",
    "\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        X, y: data\n",
    "        alpha: parameter for lasso\n",
    "    Output: Plot, initial and selected features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    # Get Feature Importance\n",
    "    importance = pd.Series(lasso.coef_, index=X.columns)\n",
    "    importance.sort_values().plot(kind=\"barh\", color=color)\n",
    "    non_zero_importance = importance[importance != 0]\n",
    "    selected_features = non_zero_importance.index\n",
    "\n",
    "    # Plot\n",
    "    plt.title(\"Lasso Feature Importance\")\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Results\n",
    "    print(f\"\\nInitial Features: {len(X.columns)}\\n\")\n",
    "    print(X.columns.tolist())\n",
    "    print(f\"\\nDecision for Numerical Features (lasso ‚â† 0): {len(selected_features.tolist())}\\n\")\n",
    "    print(selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614a16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.228825Z",
     "start_time": "2025-03-23T15:11:56.228814Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso(X_train_1_scaled, y_train_1, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969aaa2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a97773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.230110Z",
     "start_time": "2025-03-23T15:11:56.230099Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Fit the model using the training data\n",
    "model.fit(X_train_1_scaled, y_train_1)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_val_1 = model.predict(X_val_1_scaled)\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse_val_1 = np.sqrt(mean_squared_error(y_val_1, y_pred_val_1))\n",
    "print(f'Root Mean Squared Error on Validation Set: {rmse_val_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e9ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:11:56.231315Z",
     "start_time": "2025-03-23T15:11:56.231303Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(y_val_1.index, y_val_1, label='Actual Validation Values', linestyle='-', color='g')\n",
    "plt.plot(y_val_1.index, y_pred_val_1, label='Predicted Validation Values', linestyle='--', color='g')\n",
    "\n",
    "plt.plot(y_train_1.index, y_train_1, label='Actual Training Values', linestyle='-', color='b')\n",
    "\n",
    "plt.xlabel('Date/Time')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('XGBoost Forecasting: Actual vs Predicted (Training and Validation)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
